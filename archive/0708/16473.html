<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Continuing Evolution in Humans (was: A very surreal day)</title>
<meta name="Author" content="Diego Navarro (the.electric.me@gmail.com)">
<meta name="Subject" content="Re: Continuing Evolution in Humans (was: A very surreal day)">
<meta name="Date" content="2007-08-14">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Continuing Evolution in Humans (was: A very surreal day)</h1>
<!-- received="Tue Aug 14 07:44:47 2007" -->
<!-- isoreceived="20070814134447" -->
<!-- sent="Tue, 14 Aug 2007 10:40:47 -0300" -->
<!-- isosent="20070814134047" -->
<!-- name="Diego Navarro" -->
<!-- email="the.electric.me@gmail.com" -->
<!-- subject="Re: Continuing Evolution in Humans (was: A very surreal day)" -->
<!-- id="5eb0f8fd0708140640q14fab822l3f958a03ae9db131@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="873f8b0c0708140532r53918660p48145d7a79ae67f8@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Diego Navarro (<a href="mailto:the.electric.me@gmail.com?Subject=Re:%20Continuing%20Evolution%20in%20Humans%20(was:%20A%20very%20surreal%20day)"><em>the.electric.me@gmail.com</em></a>)<br>
<strong>Date:</strong> Tue Aug 14 2007 - 07:40:47 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="16474.html">Byrne Hobart: "Re: Continuing Evolution in Humans (was: A very surreal day)"</a>
<li><strong>Previous message:</strong> <a href="16472.html">Daniel: "Re: Continuing Evolution in Humans (was: A very surreal day)"</a>
<li><strong>In reply to:</strong> <a href="16472.html">Daniel: "Re: Continuing Evolution in Humans (was: A very surreal day)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="16475.html">Byrne Hobart: "Re: Continuing Evolution in Humans (was: A very surreal day)"</a>
<li><strong>Reply:</strong> <a href="16475.html">Byrne Hobart: "Re: Continuing Evolution in Humans (was: A very surreal day)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#16473">[ date ]</a>
<a href="index.html#16473">[ thread ]</a>
<a href="subject.html#16473">[ subject ]</a>
<a href="author.html#16473">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt; &gt; &gt;No. Once AIs take off, IQ will be a measure of how closely you can relate
</em><br>
<em>&gt; to
</em><br>
<em>&gt; &gt; &gt;the most powerful entities in your society. It's going to be something
</em><br>
<em>&gt; akin
</em><br>
<em>&gt; &gt; &gt;to living in the Third World and speaking fluent English.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Define the &quot;dropoff&quot; to be the rate at which reduced IQ leads to
</em><br>
<em>&gt; &gt; reduced fitness in the environment we're talking about.
</em><br>
<p>IQ basically measures how apt one is at cracking a certain kind of
<br>
computational problem -- generally involving some of the following:
<br>
<p>- deductive ability
<br>
- ability at &quot;likelihood&quot;-based induction
<br>
- pattern-matching
<br>
- principal component analysis (not necessarily &quot;classic&quot; PCA)
<br>
- clustering
<br>
<p>All of these can be solved to some point by computers now. There is no
<br>
reason to believe that a &quot;full&quot; AI, however you want to define it,
<br>
can't solve all of that. How is Y's ability to perform tasks that X
<br>
can also perform can meaningfully (for example, without any
<br>
hidden-third-cause tricks) correlate with the ability to relate with
<br>
X? (When X is a human being there's a hidden third cause in that the
<br>
ability to perform a task correlates with a common cultural background
<br>
that bonds X and Y)
<br>
<p>The general principle behind that affirmation also implies that
<br>
someone's aptitude for doing fast linear algebra and Fourier
<br>
transforms in their heads (basically autistic savants (I'm not bashing
<br>
autistics, there's a chance I'm one)) correlates to their aptitude for
<br>
scientific (numerical) programming. Do you really want to uphold a
<br>
theory that implies that?
<br>
<p>Allow me to be looser -- two anecdotes:
<br>
<p>1) I haven't inverted a matrix by hand or in my head in (many, many)
<br>
years and I must have done at most three linear regressions by hand
<br>
(and while stuck on a six-hour bus trip with no calculator and nothing
<br>
better to do). Yet I'm a working econometrician working daily with
<br>
techniques much more sophisticated than linear regressions and (a) I
<br>
have never attempted to compute an Arellano-Bond GMM estimator or a
<br>
cointegrated vector equilibrium correciton model by hand and (b) I
<br>
suck at manual linear algebra **even though I not only understand
<br>
theoretical linear algebra but also the econometric theory (which uses
<br>
linear algebra as a technique) behind the estimators I produce by
<br>
pushing buttons on my very nice professional software package produced
<br>
by Quantitative Micro Software Inc.
<br>
<p>2) I've taken a graduate-level course (meant for mathematicians) in
<br>
image processing algorithms. Don't ask me why -- it would involve
<br>
rambling on about bipolar disorders and hypomanic episodes and the
<br>
portrait of a young man trying to eat the sun. Anyway, that course --
<br>
while it was all taught in a blackboard with the help of only a
<br>
handful of image samples -- made me somewhat able at subtle color
<br>
manipulation in Adobe Photoshop to obtain certain aesthetic effects
<br>
(though I'm told by graphic designers my color tastes suck).  Yet most
<br>
people who are /very/ apt at image manipulation (and I don't mean the
<br>
&quot;erase stretch marks and flaccid buttocks&quot; kind, but the subtle color
<br>
&quot;optimization&quot;  kind) have no idea of what's going on behind the
<br>
scenes. And apparently they get a better result than me.
<br>
<p>Oh well. I think I'm killing a fly with a cannonball by now. But
<br>
really, the discussion on /what/ will differentiate humans in their
<br>
ability to relate to post-singularity Powers or whatever (I'm not keen
<br>
at sci-fi words; the singularity /is/ an event horizon) can't be based
<br>
on their current similarity to what the Powers would work like. I'd
<br>
venture it's the opposite -- what matters is how COMPLEMENTARY to the
<br>
Powers a person is.
<br>
<p>This all, of course, is based on the rather unpleasant scenario of an
<br>
&quot;unfriendly&quot; singulatiy where we're all reduced to serving a godlike
<br>
Power's needs.
<br>
<p>In a rather tangential sidenote, isn't the current research in the
<br>
mood mechanisms of the human brain transhumanist at some level? I know
<br>
I feel augmented by the psychotropic medication I've been taking, the
<br>
way (though not in the same magnitude) I venture I'd feel if I had
<br>
coprocessor chips implanted.
<br>
<p><p>2007/8/14, Daniel &lt;<a href="mailto:kopacetic101@gmail.com?Subject=Re:%20Continuing%20Evolution%20in%20Humans%20(was:%20A%20very%20surreal%20day)">kopacetic101@gmail.com</a>&gt;:
<br>
<em>&gt; 'Do you have any insight into how to influence the sharpness of the
</em><br>
<em>&gt; dropoff?  If the one or two or ten people who can best interact with
</em><br>
<em>&gt; the AI get everything, and everyone else gets nothing, then the vast
</em><br>
<em>&gt;  majority of everybody loses, and specifically I will very likely lose.'
</em><br>
<em>&gt;
</em><br>
<em>&gt; Unfortunately Tim you know as well as I do this is the way the world works.
</em><br>
<em>&gt; I wish I was wrong. The first space travellers will be the wealthy (ref. air
</em><br>
<em>&gt; travel), most likely they will also be the first to have any significant
</em><br>
<em>&gt; interaction with future AI (after the scientists who designed them). If
</em><br>
<em>&gt; &quot;Uploading&quot; were to become feasible in our lifetimes, I doubt I'd be
</em><br>
<em>&gt; anywhere near the foodchain as there would be a queue of billionaires ahead
</em><br>
<em>&gt; of me. It reminds me that in the event of a nuclear war who would be the
</em><br>
<em>&gt; people in the safest environment?  I wonder if &quot;Uploading&quot; or interaction
</em><br>
<em>&gt; with a vastly superior intelligence were available today who would be really
</em><br>
<em>&gt; be interacting/uploading?
</em><br>
<em>&gt;
</em><br>
<em>&gt; Daniel
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; On 8/8/07, Tim Freeman &lt;<a href="mailto:tim@fungible.com?Subject=Re:%20Continuing%20Evolution%20in%20Humans%20(was:%20A%20very%20surreal%20day)">tim@fungible.com</a>&gt; wrote:
</em><br>
<em>&gt; &gt; Hmm, it seems I mangled my post.  Sometimes emacs hides things.  Trying
</em><br>
<em>&gt; again:
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; From: &quot;Byrne Hobart&quot; &lt;
</em><br>
<em>&gt; <a href="mailto:sometimesfunnyalwaysright@gmail.com?Subject=Re:%20Continuing%20Evolution%20in%20Humans%20(was:%20A%20very%20surreal%20day)">sometimesfunnyalwaysright@gmail.com</a>&gt;
</em><br>
<em>&gt; &gt; &gt;No. Once AIs take off, IQ will be a measure of how closely you can relate
</em><br>
<em>&gt; to
</em><br>
<em>&gt; &gt; &gt;the most powerful entities in your society. It's going to be something
</em><br>
<em>&gt; akin
</em><br>
<em>&gt; &gt; &gt;to living in the Third World and speaking fluent English.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Define the &quot;dropoff&quot; to be the rate at which reduced IQ leads to
</em><br>
<em>&gt; &gt; reduced fitness in the environment we're talking about.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Do you have any insight into how to influence the sharpness of the
</em><br>
<em>&gt; &gt; dropoff?  If the one or two or ten people who can best interact with
</em><br>
<em>&gt; &gt; the AI get everything, and everyone else gets nothing, then the vast
</em><br>
<em>&gt; &gt; majority of everybody loses, and specifically I will very likely lose.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; If we have a choice, I hope we'll get to a situation where the dropoff
</em><br>
<em>&gt; &gt; is gentle or nonexistent, and intelligence matters very little.
</em><br>
<em>&gt; &gt; Otherwise I can't be sure I'll be on the correct side of the dividing
</em><br>
<em>&gt; &gt; line.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; --
</em><br>
<em>&gt; &gt; Tim Freeman               <a href="http://www.fungible.com">http://www.fungible.com</a>
</em><br>
<em>&gt; <a href="mailto:tim@fungible.com?Subject=Re:%20Continuing%20Evolution%20in%20Humans%20(was:%20A%20very%20surreal%20day)">tim@fungible.com</a>
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<p><p><pre>
-- 
Novidades aleatórias &amp; comentários snarky: <a href="http://twitter.com/doctork">http://twitter.com/doctork</a>
Missão: Teach dumb matter to do the Turing boogie!
Visão: Little fluffy clouds forever
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="16474.html">Byrne Hobart: "Re: Continuing Evolution in Humans (was: A very surreal day)"</a>
<li><strong>Previous message:</strong> <a href="16472.html">Daniel: "Re: Continuing Evolution in Humans (was: A very surreal day)"</a>
<li><strong>In reply to:</strong> <a href="16472.html">Daniel: "Re: Continuing Evolution in Humans (was: A very surreal day)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="16475.html">Byrne Hobart: "Re: Continuing Evolution in Humans (was: A very surreal day)"</a>
<li><strong>Reply:</strong> <a href="16475.html">Byrne Hobart: "Re: Continuing Evolution in Humans (was: A very surreal day)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#16473">[ date ]</a>
<a href="index.html#16473">[ thread ]</a>
<a href="subject.html#16473">[ subject ]</a>
<a href="author.html#16473">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:58 MDT
</em></small></p>
</body>
</html>
