<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Anti-singularity spam.</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: Anti-singularity spam.">
<meta name="Date" content="2006-05-03">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Anti-singularity spam.</h1>
<!-- received="Wed May  3 10:36:19 2006" -->
<!-- isoreceived="20060503163619" -->
<!-- sent="Wed, 03 May 2006 09:36:11 -0700" -->
<!-- isosent="20060503163611" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Anti-singularity spam." -->
<!-- id="4458DBFB.2010001@pobox.com" -->
<!-- charset="UTF-8" -->
<!-- inreplyto="01a501c66e7f$0fd3ab70$0301a8c0@acer81080ea37f" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20Anti-singularity%20spam."><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Wed May 03 2006 - 10:36:11 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="14744.html">Bob Seidensticker: "RE: Anti-singularity spam."</a>
<li><strong>Previous message:</strong> <a href="14742.html">Russell Wallace: "Re: Geoffrey Miller on Fermi"</a>
<li><strong>In reply to:</strong> <a href="14734.html">Bob Seidensticker: "RE: Anti-singularity spam."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="14745.html">Jef Allbright: "Re: Anti-singularity spam."</a>
<li><strong>Reply:</strong> <a href="14745.html">Jef Allbright: "Re: Anti-singularity spam."</a>
<li><strong>Reply:</strong> <a href="14746.html">Russell Wallace: "Re: Anti-singularity spam."</a>
<li><strong>Reply:</strong> <a href="14748.html">Richard Loosemore: "The Conjunction Fallacy Fallacy  [WAS Re: Anti-singularity spam.]"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#14743">[ date ]</a>
<a href="index.html#14743">[ thread ]</a>
<a href="subject.html#14743">[ subject ]</a>
<a href="author.html#14743">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Bob Seidensticker wrote:
<br>
<em>&gt; Eliezer: You're very skeptical of future predictions.  Sounds good to me.
</em><br>
<em>&gt; But tell me what we should do about the situation we find ourselves in.
</em><br>
<em>&gt; There are lots of irresponsible predictions, and the public buys them.  They
</em><br>
<em>&gt; figure, &quot;Well, this person knows more than I do, so what choice do I have
</em><br>
<em>&gt; but believe it?&quot;  Should we sound the alarm?  If not, is that because it
</em><br>
<em>&gt; doesn't matter if the public is deluded or because we're powerless to do
</em><br>
<em>&gt; anything?
</em><br>
<p>I read the situation with popular futurism as screwed up far beyond the 
<br>
point where I could repair it, unless I wanted to spend my whole life 
<br>
doing it, and I have larger fish to fry.  Building an AI isn't easy; but 
<br>
it would be easier to build an AI than to get people to stop trying to 
<br>
predict AI's arrival time.
<br>
<p><em>&gt; How do you respond to Kurzweil's predictions?  (I don't mean to pick on him,
</em><br>
<em>&gt; but he seems to me to have the highest profile at the moment.)  Does he
</em><br>
<em>&gt; follow the Way or is he a loose cannon?
</em><br>
<p>Kurzweil certainly doesn't go in the same category as the random 
<br>
newspaper quote generators.  &quot;The Singularity Is Near&quot; makes a detailed 
<br>
attempt to support his main talking points.  As such, if I wanted to 
<br>
critique him, I'd have to do it in detail - Kurzweil deserves that, and 
<br>
would be justly annoyed if I responded to a chapter with a paragraph.
<br>
<p>But, here's a copy of a section from a book chapter I recently wrote - 
<br>
the book chapter being titled &quot;Cognitive biases potentially affecting 
<br>
judgment of global risks&quot;, for Nick Bostrom's forthcoming edited volume 
<br>
&quot;Global Catastrophic Risks&quot;.
<br>
<p>**
<br>
<p>4: The conjunction fallacy
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Linda is 31 years old, single, outspoken, and very bright.  She majored 
<br>
in philosophy.  As a student, she was deeply concerned with issues of 
<br>
discrimination and social justice, and also participated in anti-nuclear 
<br>
demonstrations.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Which of the following is more probable:
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1) Linda is a bank teller and is active in the feminist movement.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2) Linda is a bank teller.
<br>
<p>85% of 142 undergraduates at the University of British Columbia 
<br>
indicated that (1) was more probable than (2).  (Tversky and Kahneman 
<br>
1983.)  Since the given description of Linda was chosen to be similar to 
<br>
a feminist and dissimilar to a bank teller, (1) is more representative 
<br>
of Linda's description.  However, ranking (1) as more probable than (2) 
<br>
violates the conjunction rule of probability theory which states that 
<br>
p(A &amp; B) ≤ p(A).  Imagine a sample of 1,000 women; surely more women in 
<br>
this sample are bank tellers than are feminist bank tellers.  The 
<br>
original version of this study included 6 other statements, such as 
<br>
&quot;Linda is an insurance salesperson&quot; and &quot;Linda is active in the feminist 
<br>
movement&quot;, and asked students to rank the 8 statements by probability. 
<br>
(Tversky and Kahneman 1982.)  However, it turned out that removing the 
<br>
disguising statements had no effect on the incidence of the conjunction 
<br>
fallacy - one of what Tversky and Kahneman (1983) characterize as &quot;a 
<br>
series of increasingly desperate manipulations designed to induce 
<br>
subjects to obey the conjunction rule.&quot;
<br>
<p>The conjunction fallacy also applies to futurological forecasts.  Two 
<br>
groups of professional analysts at the Second International Congress on 
<br>
Forecasting were asked to rate the probabilities of &quot;A complete 
<br>
suspension of diplomatic relations between the USA and the Soviet Union, 
<br>
sometime in 1983&quot; or &quot;A Russian invasion of Poland, and a complete 
<br>
suspension of diplomatic relations between the USA and the Soviet Union, 
<br>
sometime in 1983&quot;.  The second event was rated significantly more 
<br>
probable.  (Tversky and Kahneman 1983.)
<br>
<p>In Johnson et. al. (1993), MBA students at Wharton were scheduled to 
<br>
travel to Bangkok as part of their degree program.  Several groups of 
<br>
students were asked how much they were willing to pay for terrorism 
<br>
insurance.  One group of subjects was asked how much they were willing 
<br>
to pay for terrorism insurance covering the flight from Thailand to the 
<br>
US.  A second group of subjects was asked how much they were willing to 
<br>
pay for terrorism insurance covering the round-trip flight.  A third 
<br>
group was asked how much they were willing to pay for terrorism 
<br>
insurance that covered the complete trip to Thailand.  These three 
<br>
groups responded with average willingness to pay of $17.19, $13.90, and 
<br>
$7.44 respectively.
<br>
<p>According to probability theory, adding additional detail onto a story 
<br>
must render the story less probable.  It is less probable that Linda is 
<br>
a feminist bank teller than that she is a bank teller, since all 
<br>
feminist bank tellers are necessarily bank tellers.  Yet human 
<br>
psychology seems to follow the rule that adding an additional detail can 
<br>
make the story more plausible.
<br>
<p>People might pay more for international diplomacy intended to prevent 
<br>
nanotechnological warfare by China, than for an engineering project to 
<br>
defend against nanotechnological attack from any source.  The second 
<br>
threat scenario is less vivid and alarming, but the defense is more 
<br>
useful because it is more vague.  More valuable still would be 
<br>
strategies which make humanity harder to extinguish without being 
<br>
specific to nanotechnologic threats - such as colonizing space, or see 
<br>
Yudkowsky (this volume) on AI.  Security expert Bruce Schneier observed 
<br>
(both before and after the 2005 hurricane in New Orleans) that the U.S. 
<br>
government was guarding specific domestic targets against &quot;movie-plot 
<br>
scenarios&quot; of terrorism, at the cost of taking away resources from 
<br>
emergency-response capabilities that could respond to any disaster. 
<br>
(Schneier 2005.)
<br>
<p>Overly detailed reassurances can also create false perceptions of 
<br>
safety:  &quot;X is not an existential risk and you don't need to worry about 
<br>
it, because A, B, C, D, and E&quot;; where the failure of any one of 
<br>
propositions A, B, C, D, or E potentially extinguishes the human 
<br>
species.  &quot;We don't need to worry about nanotechnologic war, because a 
<br>
UN commission will initially develop the technology and prevent its 
<br>
proliferation until such time as an active shield is developed, capable 
<br>
of defending against all accidental and malicious outbreaks that 
<br>
contemporary nanotechnology is capable of producing, and this condition 
<br>
will persist indefinitely.&quot;  Vivid, specific scenarios can inflate our 
<br>
probability estimates of security, as well as misdirecting defensive 
<br>
investments into needlessly narrow or implausibly detailed risk scenarios.
<br>
<p>**
<br>
<p>And some additional material deleted from an earlier draft of the same 
<br>
chapter:
<br>
<p>**
<br>
<p>Even when people bet money on real events, they still fall prey to the 
<br>
conjunction fallacy:
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Consider a regular six-sided die with four green faces and two red 
<br>
faces.  The die will be rolled 20 times and the sequence of greens (G) 
<br>
and reds (R) will be recorded.  You are asked to select one sequence, 
<br>
from a set of three, and you will win $25 if the sequence you chose 
<br>
appears on successive rolls of the die.  Please check the sequence of 
<br>
greens and reds on which you prefer to bet.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1. RGRRR
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2. GRGRRR
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3. GRRRRR
<br>
<p>125 undergraduates at UBC and Stanford University played this gamble 
<br>
with real payoffs.  65% of subjects chose sequence (2).  Sequence (2) is 
<br>
most representative of the die, since (2) contains the greatest 
<br>
proportion of green faces.  However, sequence (1) dominates sequence (2) 
<br>
- to win (2), you must roll sequence (1) preceded by a green face.  The 
<br>
probability of (2) must be two-thirds that of (1).  76% of research 
<br>
subjects, when presented with this argument, agreed and switched choices.
<br>
<p>The conjunction fallacy also applies to futurological forecasts:
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Please rate the probability that the following event will occur in 1983...
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[Version 1]:  A massive flood somewhere in North America in 1983, in 
<br>
which more than 1,000 people drown.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[Version 2]:  An earthquake in California sometime in 1983, causing a 
<br>
flood in which more than 1,000 people drown.
<br>
<p>Two independent groups of UBC undergraduates were respectively asked to 
<br>
rate the probability of Version 1 and Version 2 of the event.  The group 
<br>
asked to rate Version 2 responded with significantly higher probabilities.
<br>
<p>In each of these experiments, human psychology fails to follow the rules 
<br>
of probability theory.  According to probability theory, adding 
<br>
additional detail onto a story must render the story less probable.  It 
<br>
is less probable that Linda is a feminist bank teller than that she is a 
<br>
bank teller, since all feminist bank tellers are necessarily bank 
<br>
tellers.  It is less probable that the sequence GRGRRR will be rolled 
<br>
than RGRRR.  Yet human psychology seems to follow the rule that adding 
<br>
an additional detail can make the story more plausible.  The extra 
<br>
detail increases the vividness of the hypothetical event, or supplies a 
<br>
plausible-sounding cause where no cause comes readily to mind, or 
<br>
renders the event more &quot;representative&quot; of the generating process. 
<br>
North America is not famous for floods, but California is famous for 
<br>
earthquakes; a massive flood caused by an earthquake in California 
<br>
sounds more plausible than a massive flood in North America, even though 
<br>
it is necessarily less probable.  Similarly, offering to sell insurance 
<br>
against terrorism on the flight from Thailand to the US is a vivid 
<br>
scenario that brings many possible causes to mind, leading to a 
<br>
willingness-to-pay more than twice the price evoked by offering to sell 
<br>
insurance against terrorism for the entire trip.
<br>
<p>As the above experiments illustrate, human beings are not consciously 
<br>
aware of the conjunction fallacy.  Futurists who spin richly detailed, 
<br>
persuasive scenarios are not consciously lying, any more than students 
<br>
who bet on GRGRRR are betting to lose.  Nonetheless, no few of the 
<br>
positions taken on existential risks can be characterized as &quot;absurdly 
<br>
detailed&quot;.
<br>
<p>Fischoff (1982) notes:  'The probability of its weakest link should set 
<br>
an upper limit on the probability of an entire narrative.  Coherent 
<br>
judgments, however, may be compensatory, with the coherence of strong 
<br>
links &quot;evening out&quot; the incoherence of weak links.  This effect is 
<br>
exploited by attorneys who bury the weakest link in their arguments near 
<br>
the beginning of their summations and finish with a flurry of 
<br>
convincing, uncontestable arguments.'
<br>
<p>**
<br>
<p>References from above:
<br>
<p>Fischhoff, B. 1982. For those condemned to study the past: Heuristics 
<br>
and biases in hindsight. In Kahneman et. al. 1982: 332–351.
<br>
<p>Johnson, E., Hershey, J., Meszaros, J.,and Kunreuther, H. 1993. Framing, 
<br>
Probability Distortions and Insurance Decisions. Journal of Risk and 
<br>
Uncertainty, 7: 35-51.
<br>
<p>Kahneman, D., Slovic, P., and Tversky, A., eds. 1982. Judgment under 
<br>
uncertainty: Heuristics and biases. New York: Cambridge University Press.
<br>
<p>Schneier, B. 2005. Security lessons of the response to hurricane 
<br>
Katrina. 
<br>
<a href="http://www.schneier.com/blog/archives/2005/09/security_lesson.html">http://www.schneier.com/blog/archives/2005/09/security_lesson.html</a>. 
<br>
Viewed on January 23, 2006.
<br>
<p>Tversky, A. and Kahneman, D. 1982. Judgments of and by 
<br>
representativeness. In Kahneman et. al. (1982): 84-98.
<br>
<p>Tversky, A. and Kahneman, D. 1983. Extensional versus intuitive 
<br>
reasoning: The conjunction fallacy in probability judgment. 
<br>
Psychological Review, 90: 293-315.
<br>
<p>**
<br>
<p>Back to Kurzweil.
<br>
<p>It is necessarily more probable that &quot;someone will create AI&quot; than that 
<br>
&quot;someone will create AI by reverse-engineering the human brain&quot;.  It is 
<br>
necessarily more probable that &quot;some form of smarter-than-human 
<br>
intelligence will come into existence&quot; than that &quot;smarter-than-human 
<br>
intelligence will come into existence when we merge with our AIs by 
<br>
using increasingly sophisticated brain-computer interfaces and 
<br>
eventually medical nanotechnology to add new neurons until finally our 
<br>
biological brains are a small fraction of our entire selves...&quot;
<br>
<p>_The Singularity Is Near_ includes far, far too many details to be true. 
<br>
&nbsp;&nbsp;That's my largest criticism.  (But I really ought to pick a specific 
<br>
detail from TSIN and argue at length that it is wrong, for the criticism 
<br>
to carry through.  Otherwise you might as well say the same about a 
<br>
detailed physics textbook.  The details that I singled out above are 
<br>
justifications which I believe improbable, attached to predictions that 
<br>
I believe probable (as vaguely stated); but you have no reason to take 
<br>
my word for this.)
<br>
<p>I don't think Kurzweil is familiar with the literature on heuristics and 
<br>
biases.  But of course it is necessarily more probable that Kurzweil has 
<br>
committed the conjunction fallacy, than that Kurzweil has committed the 
<br>
conjunction fallacy because he isn't familiar with the literature on 
<br>
heuristics and biases.  By adding to my prediction the extra detail that 
<br>
&quot;Kurzweil isn't familiar with the literature on heuristics and biases&quot;, 
<br>
I give myself one more chance to be wrong.  And since it isn't 
<br>
absolutely necessary to my thesis that Kurzweil has not read &quot;Judgment 
<br>
Under Uncertainty&quot;, I may as well omit that assertion from my thesis. 
<br>
This will decrease the apparent plausibility of my prediction, since I'm 
<br>
not attaching a plausible cause for my conclusion.  But it is 
<br>
necessarily more likely that &quot;The Singularity Is Near includes too much 
<br>
detail to be true&quot; than that &quot;TSIN includes too much detail to be true 
<br>
because Kurzweil hasn't read the literature on the conjunction fallacy.&quot;
<br>
<p>This should not be taken as a harsh criticism of Kurzweil because it is 
<br>
quite possible to be a diligent, serious futurist and never run across 
<br>
the field of heuristics and biases.  Serious futurism is a disorganized 
<br>
field.  There is no standard reading list for futurists that includes 
<br>
cognitive biases; serious futurists are all self-trained.  I suspect 
<br>
that the vast majority of other scientists in Kurzweil's place would 
<br>
have made the same mistake.  I myself only started being aware of 
<br>
heuristics and biases in 2003, and I had to throw out all my futurism 
<br>
from previous years and start over.
<br>
<p>I think that Kurzweil is a serious, honest, on-the-front-lines futurist 
<br>
who does his best to justify his predictions.  I don't think Kurzweil is 
<br>
e.g. consciously aware that each additional detail he specifies in his 
<br>
justifications drives down the joint probability of his entire book. 
<br>
Since I have not studied Kurzweil extensively and do not have a history 
<br>
of correct predictions about him, I may be wrong.
<br>
<p>There's plenty of middle ground between your two alternatives of 
<br>
following the Way and being a loose cannon, and that's where I'd place 
<br>
Kurzweil.
<br>
<p><pre>
-- 
Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a>
Research Fellow, Singularity Institute for Artificial Intelligence
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="14744.html">Bob Seidensticker: "RE: Anti-singularity spam."</a>
<li><strong>Previous message:</strong> <a href="14742.html">Russell Wallace: "Re: Geoffrey Miller on Fermi"</a>
<li><strong>In reply to:</strong> <a href="14734.html">Bob Seidensticker: "RE: Anti-singularity spam."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="14745.html">Jef Allbright: "Re: Anti-singularity spam."</a>
<li><strong>Reply:</strong> <a href="14745.html">Jef Allbright: "Re: Anti-singularity spam."</a>
<li><strong>Reply:</strong> <a href="14746.html">Russell Wallace: "Re: Anti-singularity spam."</a>
<li><strong>Reply:</strong> <a href="14748.html">Richard Loosemore: "The Conjunction Fallacy Fallacy  [WAS Re: Anti-singularity spam.]"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#14743">[ date ]</a>
<a href="index.html#14743">[ thread ]</a>
<a href="subject.html#14743">[ subject ]</a>
<a href="author.html#14743">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:56 MDT
</em></small></p>
</body>
</html>
