<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Mindless Thought Experiments</title>
<meta name="Author" content="John K Clark (johnkclark@fastmail.fm)">
<meta name="Subject" content="Mindless Thought Experiments">
<meta name="Date" content="2008-03-01">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Mindless Thought Experiments</h1>
<!-- received="Sat Mar  1 11:31:57 2008" -->
<!-- isoreceived="20080301183157" -->
<!-- sent="Sat, 01 Mar 2008 10:28:58 -0800" -->
<!-- isosent="20080301182858" -->
<!-- name="John K Clark" -->
<!-- email="johnkclark@fastmail.fm" -->
<!-- subject="Mindless Thought Experiments" -->
<!-- id="1204396138.23610.1240003049@webmail.messagingengine.com" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="3cf171fe0802291356j33285b7dk918aca5109aefac9@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> John K Clark (<a href="mailto:johnkclark@fastmail.fm?Subject=Re:%20Mindless%20Thought%20Experiments"><em>johnkclark@fastmail.fm</em></a>)<br>
<strong>Date:</strong> Sat Mar 01 2008 - 11:28:58 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="17684.html">sl4.20.pris@spamgourmet.com: "How many on this list practice speed reading?"</a>
<li><strong>Previous message:</strong> <a href="../0802/17682.html">Matt Mahoney: "Re: OpenCog Concerns"</a>
<li><strong>In reply to:</strong> <a href="../0802/17678.html">Ben Goertzel: "Re: OpenCog Concerns"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="17690.html">Nick Tarleton: "Re: Mindless Thought Experiments"</a>
<li><strong>Reply:</strong> <a href="17690.html">Nick Tarleton: "Re: Mindless Thought Experiments"</a>
<li><strong>Maybe reply:</strong> <a href="17813.html">Matt Mahoney: "Re: Mindless Thought Experiments"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#17683">[ date ]</a>
<a href="index.html#17683">[ thread ]</a>
<a href="subject.html#17683">[ subject ]</a>
<a href="author.html#17683">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
About a week ago I sent the following to Jaron Lanier, I did not receive
<br>
a
<br>
reply:
<br>
<p>=========
<br>
<p>I read your article &quot;Mindless Thought Experiments&quot; at:
<br>
<a href="http://www.jaronlanier.com/aichapter.html">http://www.jaronlanier.com/aichapter.html</a>
<br>
<p>I have a few comments.
<br>
<p><em>&gt; let's assume that software is a legitimate medium for
</em><br>
<em>&gt; consciousness and move on.
</em><br>
<p>No, Let's not move on. Software is very important but it's inert unless
<br>
there is hardware it can run on.
<br>
<p><em>&gt; start searching through all the possible computers that
</em><br>
<em>&gt; could exist up to a certain very large size until you find
</em><br>
<em>&gt; one that treats the raindrop positions as a program that
</em><br>
<em>&gt; is exactly equivalent to your brain.
</em><br>
<p>OK.
<br>
<p><em>&gt;Yes, it can be done
</em><br>
<p>I know.
<br>
<p><em>&gt; so is the rainstorm conscious?
</em><br>
<p>Well it certainly doesn't behave intelligently and I would concede it is
<br>
conscious only when you show me how a stack of papers that contains
<br>
the source code for a very good chess program can beat a grandmaster.
<br>
<p>Nobody is saying pure information can do anything, it must be
<br>
incorporated
<br>
into matter, but the important point is that the matter you use can be
<br>
generic, any old matter will do.
<br>
<p><em>&gt; You say the rainstorm isn't really doing computation
</em><br>
<em>&gt; it's just sitting there as a passive program- so it
</em><br>
<em>&gt; doesn't count? Fine, then we'll measure a larger
</em><br>
<em>&gt; rainstorm and search for a new computer that treats
</em><br>
<em>&gt; a larger collection of raindrops as implementing BOTH
</em><br>
<em>&gt; the computer we found before that runs your brain as
</em><br>
<em>&gt; raindrops AS WELL AS your brain in raindrops.
</em><br>
<p>So now in addition to a pile of paper consisting of the source code of a
<br>
very good chess program there is in addition another pile of paper
<br>
consisting of the blueprints of a very good computer; but I still don't
<br>
think both those piles of paper together can beat you at a game of
<br>
chess.
<br>
Printing out more paper won't help. Sooner or later somebody is going to
<br>
have to build something.
<br>
<p><em>&gt; The thought experiment supply store can ship us an
</em><br>
<em>&gt; even better sensor that can measure the motions,
</em><br>
<em>&gt; not merely the instant positions, of all the raindrops
</em><br>
<em>&gt; in a storm over a period of time.
</em><br>
<p>Sensor? How can pure information sense anything? And in fact I can't
<br>
quite
<br>
see how information could be stored or processed without matter and
<br>
energy being involved somewhere down the line.
<br>
<p>Your rainstorm contains a trivial amount of information needed for an
<br>
intelligence; you also need to specify exactly what sort of computer
<br>
hardware this rain program will run on. And the distinction between
<br>
hardware and software can become very fuzzy indeed if you consider
<br>
hardware as atoms organized in a way specified by information.
<br>
<p>If you don't agree with this then you'd have to take seriously my claim
<br>
to
<br>
have a revolutionarily data compressing algorithm that can compress the
<br>
entire Vista operating system into one bit; you just have to use the
<br>
right
<br>
computer. If the bit is a zero the computer produces gibberish, but if
<br>
the
<br>
bit is a 1 the computer runs Vista that is hardwired in.
<br>
<p><em>&gt; You might object that the raindrops are not
</em><br>
<em>&gt; influencing each other, so they are still passive,
</em><br>
<em>&gt; as far as computing your brain is concerned.
</em><br>
<em>&gt; Let's switch instead, then, to a large swarm of
</em><br>
<em>&gt; asteroids hurdling through space. They all exert
</em><br>
<em>&gt; gravitational pull on each other. Now we'll use a
</em><br>
<em>&gt; sensor for asteroid swarm internal motion and
</em><br>
<em>&gt; use it to get data that will be matched to an
</em><br>
<em>&gt; appropriate computer to implement your brain.
</em><br>
<em>&gt; Now you have a physical system whose internal
</em><br>
<em>&gt; interactions perform the computation of your mind.
</em><br>
<p>A &quot;mind&quot; that fails the Turing Test, and fails it about as spectacularly
<br>
as can be imagined.
<br>
<p><em>&gt; A few DO take the bait and choose to believe
</em><br>
<em>&gt; there are a myriad of consciousnesses everywhere.
</em><br>
<em>&gt; This has got to be the least elegant position ever
</em><br>
<em>&gt; taken on any subject in the history of science.
</em><br>
<p>I would say it is the second least elegant position in the history of
<br>
science because all your arguments, to the affect they have any force at
<br>
all, could just as easily be used to &quot;prove&quot; that consciousness does not
<br>
exist anywhere in the universe.
<br>
<p>Well ok, I suppose you could still say that Jaron Lanier is conscious
<br>
because you know that from direct experience and direct experience
<br>
outranks the scientific method or even logic; but you'd have absolutely
<br>
no reason to think any of your fellow human beings are conscious.
<br>
<p><em>&gt; AI proponents usually seize on some specific stage
</em><br>
<em>&gt; in my reducto ad absurdum to locate the point
</em><br>
<em>&gt; where I've gone too far.
</em><br>
<p>I believe if you're going to attempt a reducto ad absurdum proof care
<br>
must
<br>
be taken to ensure that your conclusion is contradictory and not just
<br>
odd.
<br>
Einstein also came up with a thought experiment, he thought it proved
<br>
that
<br>
Quantum Mechanics must be wrong because otherwise things would be odd;
<br>
not illogical, not contradictory, just odd. In the last few years this
<br>
thought experiment (Bell's Inequality) was actually performed and now we
<br>
know that things are indeed odd.
<br>
<p><em>&gt; to the right alien, it might appear that people do
</em><br>
<em>&gt; nothing, and asteroid swarms are acting consciously.
</em><br>
<p>That would be very odd indeed, but as we have no way of communicating
<br>
with such an alien or it to us there is little more that can be said
<br>
about
<br>
the matter.
<br>
<p>Somewhere in the universe there may be a language where this Email,
<br>
without changing a single character, expresses in perfect grammar the
<br>
instructions on how to operate a new type of can opener; but as neither
<br>
of us knows that language there is little danger of this conversation
<br>
being diverted into a discussion of can opener technology.
<br>
<p><em>&gt; In the following discussion, I'll let the terms &quot;smart&quot;
</em><br>
<em>&gt; and &quot;conscious&quot; blur together, even though I
</em><br>
<em>&gt; profoundly disagree that they are interchangeable.
</em><br>
<p>I've been asking people with ideas like yours this question for decades
<br>
but
<br>
I've never received a straight answer, not one:
<br>
<p>If intelligence is not always linked to consciousness then why on Earth
<br>
did
<br>
evolution produce it?
<br>
<p>After all, however important our inner life is to us it is invisible to
<br>
natural selection; indeed the reason you think the Turing Test does not
<br>
work is exactly because you believe behavior is not linked to
<br>
consciousness. And yet we know with absolute positive 100% certainty
<br>
that evolution did produce at least one being who was conscious.
<br>
But why? How?
<br>
<p>However if consciousness is just what information feels like when it is
<br>
being processed then all would be explained. If Turing was wrong then
<br>
so was Darwin. I do not think Darwin was wrong. I really don't.
<br>
<p>It is also interesting that the parts of the brain that produce emotion
<br>
(and
<br>
presumably you think emotion has something to do with consciousness)
<br>
are hundreds of millions of years old, but the parts of the brain that
<br>
produce the sort of intelligence we are so proud of are only about one
<br>
million years old.
<br>
<p>So if evolution found it easier to come up with consciousness than
<br>
intelligence I don't see why we would find the opposite to be true; you
<br>
could make a stronger case saying a computer may be conscious
<br>
someday but it will never be intelligent; although I think it will be
<br>
both.
<br>
<p><em>&gt; AI has been one of the most funded, and least
</em><br>
<em>&gt; bountiful, areas of scientific inquiry in the
</em><br>
<em>&gt; second half of the twentieth century. It keeps
</em><br>
<em>&gt; on failing and bouncing back with a different name
</em><br>
<p>Speaking of changing names, the reason AI seems to make so little
<br>
progress is that as soon as a computer can do something it is decided
<br>
that the thing in question does not really require intelligence after
<br>
all.
<br>
Fifty years ago everybody and I do mean everybody, thought that solving
<br>
equations or playing a great game of Chess required intelligence.
<br>
No more. Fifteen years ago everybody thought it would take a great deal
<br>
of intelligence for a librarian to do what Google does. No more.
<br>
Intelligence is whatever a computer can't do, YET.
<br>
<p><em>&gt; the moral &quot;equal rights&quot; argument for the
</em><br>
<em>&gt; machine's benefit.
</em><br>
<p>It is of academic interest only if we should treat an intelligent
<br>
machine
<br>
morally; it is much more than of academic interest if the machine should
<br>
treat us morally. like it or not the future belongs to the machines not
<br>
to
<br>
us.
<br>
<p><em>&gt; This is where AI crosses a boundary and
</em><br>
<em>&gt; turns into a religion.
</em><br>
<p>Only if you think religion should have a monopoly on the deepest
<br>
questions. I don't.
<br>
<p><em>&gt; Hans Moravec is one researcher who
</em><br>
<em>&gt; explicitly hopes for this eventuality.
</em><br>
<p>Me too.
<br>
<p><em>&gt; If we can become machines we don't have to die,
</em><br>
<em>&gt; but only if we believe in machine consciousness.
</em><br>
<p>And only if we are astronomically lucky. Still, given the choice between
<br>
slim chance and no chance I'll pick slim chance any day.
<br>
<p><em>&gt; Alan Turing proposed a test in which a computer
</em><br>
<em>&gt; and a person are placed in isolation booths and
</em><br>
<em>&gt; are only allowed to communicate via media that
</em><br>
<em>&gt; conceal their identities, such as typed emails.
</em><br>
<p>And that is exactly what we are doing right now. I disagree with much in
<br>
your article but I still think it was written by an intelligent
<br>
conscious
<br>
being. Do you think the same about me? Do you think that I, the writer
<br>
of
<br>
this Email, am conscious? I can't imagine why you would think such a
<br>
ridiculous thing as you don't think the Turing Test is any good.
<br>
<p>&nbsp;John K Clark     <a href="mailto:jonkc@att.net?Subject=Re:%20Mindless%20Thought%20Experiments">jonkc@att.net</a>
<br>
<p><p><pre>
-- 
  John K Clark
  <a href="mailto:johnkclark@fastmail.fm?Subject=Re:%20Mindless%20Thought%20Experiments">johnkclark@fastmail.fm</a>
-- 
<a href="http://www.fastmail.fm">http://www.fastmail.fm</a> - And now for something completely different…
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="17684.html">sl4.20.pris@spamgourmet.com: "How many on this list practice speed reading?"</a>
<li><strong>Previous message:</strong> <a href="../0802/17682.html">Matt Mahoney: "Re: OpenCog Concerns"</a>
<li><strong>In reply to:</strong> <a href="../0802/17678.html">Ben Goertzel: "Re: OpenCog Concerns"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="17690.html">Nick Tarleton: "Re: Mindless Thought Experiments"</a>
<li><strong>Reply:</strong> <a href="17690.html">Nick Tarleton: "Re: Mindless Thought Experiments"</a>
<li><strong>Maybe reply:</strong> <a href="17813.html">Matt Mahoney: "Re: Mindless Thought Experiments"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#17683">[ date ]</a>
<a href="index.html#17683">[ thread ]</a>
<a href="subject.html#17683">[ subject ]</a>
<a href="author.html#17683">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:02 MDT
</em></small></p>
</body>
</html>
