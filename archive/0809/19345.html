<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=WINDOWS-1252">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: [sl4] A model of RSI</title>
<meta name="Author" content="Mikael Hall (mikael.hall@gmail.com)">
<meta name="Subject" content="Re: [sl4] A model of RSI">
<meta name="Date" content="2008-09-16">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: [sl4] A model of RSI</h1>
<!-- received="Tue Sep 16 18:17:30 2008" -->
<!-- isoreceived="20080917001730" -->
<!-- sent="Wed, 17 Sep 2008 02:14:45 +0200" -->
<!-- isosent="20080917001445" -->
<!-- name="Mikael Hall" -->
<!-- email="mikael.hall@gmail.com" -->
<!-- subject="Re: [sl4] A model of RSI" -->
<!-- id="dc5d815f0809161714m23985d61gae46d78901b19ce0@mail.gmail.com" -->
<!-- charset="WINDOWS-1252" -->
<!-- inreplyto="595898.4002.qm@web51903.mail.re2.yahoo.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Mikael Hall (<a href="mailto:mikael.hall@gmail.com?Subject=Re:%20[sl4]%20A%20model%20of%20RSI"><em>mikael.hall@gmail.com</em></a>)<br>
<strong>Date:</strong> Tue Sep 16 2008 - 18:14:45 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="19346.html">Stuart Armstrong: "Re: [sl4] A model of RSI"</a>
<li><strong>Previous message:</strong> <a href="19344.html">Matt Mahoney: "Re: [sl4] A model of RSI"</a>
<li><strong>In reply to:</strong> <a href="19344.html">Matt Mahoney: "Re: [sl4] A model of RSI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="19346.html">Stuart Armstrong: "Re: [sl4] A model of RSI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#19345">[ date ]</a>
<a href="index.html#19345">[ thread ]</a>
<a href="subject.html#19345">[ subject ]</a>
<a href="author.html#19345">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
I think you have many valid points but I can't manage to agree visavi
<br>
evolution. In fact I believe dissolving your confusion is interesting and
<br>
illuminating.
<br>
<p>Ok. To me &quot;competition&quot; is to &quot;evolution&quot; the same way &quot;ability to solve
<br>
problems&quot; is to &quot;intelligence&quot;.
<br>
And, to me, you are using 'evolution' where 'competition' should be used:
<br>
(note
<br>
Let 'outin' be defined/examplified by &quot;competition&quot; and &quot;ability&quot;.
<br>
Let 'inout' be defined/examplified by &quot;evolution&quot; and &quot;intelligence&quot;.)
<br>
<p>Computers are good at fullfilling goals but not in choosing goals, therefore
<br>
computes are stupid. So ability on its own is not enough  to make
<br>
intelligence. Most people seem to believe this. I believe likewise that
<br>
competition is &quot;stupid&quot; and not enough to make evolution. Also, if one were
<br>
to put the concept of &quot;goals&quot; in relation to that picture, you would put
<br>
&quot;goal choosing&quot; in the inout box and &quot;goal fullfillment&quot; in the outin box.
<br>
Discussing self improving systems in terms of  goalchoosing/inout
<br>
goalfullfillment/outin is crucial.
<br>
<p>In fact, the almost complete separation of 'outin' (no danger around you -do
<br>
what you please) and 'inout' (something is happening - look around to find
<br>
out what it is) accomplished by letting programmed computers do things is
<br>
very related to the basic concern of sl4. This is a very basic fact - we
<br>
don't first and foremost need computers with human like behaivour. The basic
<br>
drive for the development of computing is goalfullfillment not goalchoosing.
<br>
It's the freedom of goalchoosing man strive to attain, and the easyness by
<br>
which man can choose goals for goal fullfilling entities has been a long
<br>
subject for war, thought and lambda calculus. And political ideologies gives
<br>
views &quot;freedom of goal choosing&quot; should mean just the same way we might try
<br>
to control possible goalfullfillers which we are'nt able to choose goals
<br>
for. In the late 1800'reds Russia started to loose control over their
<br>
goalfullfillers, now we fear loosing control over ours.
<br>
<p>I don't have development towards transhuman intelligence as the primary
<br>
concern. I regard the increasing stupidification of goalfullfillment (inout
<br>
marginalisation), together with accelerating goalfullfillment rate, to be
<br>
the most pressing concern. All supereffective goalfullfillers are
<br>
potentially very dangerous, especially when we do not choose the goals.
<br>
Secondly, what happens when humans no longer can aspire to be
<br>
goalfullfillers - ownership wars?, extinction?. I do not dare to simply hope
<br>
for rapid prohuman superintelligence - the relationship between
<br>
goalfullfillment, goalchoosing and mankind must be discussed.
<br>
<p>Kind Regards
<br>
Mikael Hall
<br>
<p>2008/9/16 Matt Mahoney &lt;<a href="mailto:matmahoney@yahoo.com?Subject=Re:%20[sl4]%20A%20model%20of%20RSI">matmahoney@yahoo.com</a>&gt;
<br>
<p><em>&gt; I think you are right that we can't distinguish between code and data. If
</em><br>
<em>&gt; we use the definitions in my paper then there is no difference between RSI
</em><br>
<em>&gt; (the program rewriting itself) and a simple program with a goal (meaning
</em><br>
<em>&gt; that the utility of the output would increase if its run time limit were
</em><br>
<em>&gt; relaxed).
</em><br>
<em>&gt;
</em><br>
<em>&gt; So how could RSI be defined in a meaningful way?
</em><br>
<em>&gt;
</em><br>
<em>&gt; Some examples I might consider to be self improvement:
</em><br>
<em>&gt;
</em><br>
<em>&gt; - Accumulating knowledge on how to better accumulate and use knowledge.
</em><br>
<em>&gt; - Books on how to write books.
</em><br>
<em>&gt; - Computer aided software engineering.
</em><br>
<em>&gt; - Computer aided hardware design of faster computers.
</em><br>
<em>&gt; - Genetically engineering humans for larger brains.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Some examples I would NOT consider RSI:
</em><br>
<em>&gt;
</em><br>
<em>&gt; - Machine learning.
</em><br>
<em>&gt; - Human education.
</em><br>
<em>&gt; - Evolution.
</em><br>
<em>&gt; - Development of language and culture.
</em><br>
<em>&gt; - Economic development.
</em><br>
<em>&gt;
</em><br>
<em>&gt; The distinction I want to make is that RSI does not make use of external
</em><br>
<em>&gt; information not available at the start. Specifically, the agents who execute
</em><br>
<em>&gt; the improvement algorithm must know what the goal is, how to compute it, and
</em><br>
<em>&gt; how to test themselves and/or their offspring as to whether they are making
</em><br>
<em>&gt; progress toward this goal. In my examples of non-RSI, the agents and the
</em><br>
<em>&gt; systems have different goals. The teacher has different goals than the
</em><br>
<em>&gt; student. Evolution has the &quot;goal&quot; of increasing competitive fitness, which
</em><br>
<em>&gt; is at odds with the goals of agents that want to eat, have sex, and not die.
</em><br>
<em>&gt; The economy has a &quot;goal&quot; of producing a complex organization that can
</em><br>
<em>&gt; support a large population efficiently, as opposed to the goals of
</em><br>
<em>&gt; individuals to acquire money.
</em><br>
<em>&gt;
</em><br>
<em>&gt; So how can this idea be expressed formally as a property of Turing
</em><br>
<em>&gt; machines?
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; -- Matt Mahoney, <a href="mailto:matmahoney@yahoo.com?Subject=Re:%20[sl4]%20A%20model%20of%20RSI">matmahoney@yahoo.com</a>
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; --- On Mon, 9/15/08, Denis &lt;<a href="mailto:dnsflex@yahoo.com?Subject=Re:%20[sl4]%20A%20model%20of%20RSI">dnsflex@yahoo.com</a>&gt; wrote:
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt; From: Denis &lt;<a href="mailto:dnsflex@yahoo.com?Subject=Re:%20[sl4]%20A%20model%20of%20RSI">dnsflex@yahoo.com</a>&gt;
</em><br>
<em>&gt; &gt; Subject: Re: [sl4] A model of RSI
</em><br>
<em>&gt; &gt; To: <a href="mailto:sl4@sl4.org?Subject=Re:%20[sl4]%20A%20model%20of%20RSI">sl4@sl4.org</a>
</em><br>
<em>&gt; &gt; Date: Monday, September 15, 2008, 4:09 PM
</em><br>
<em>&gt; &gt; I think if &quot;RSI&quot; mean a program searching to
</em><br>
<em>&gt; &gt; improve its behaviour without using others data can be a
</em><br>
<em>&gt; &gt; good idea but it is very different to a &quot;rewriting
</em><br>
<em>&gt; &gt; itself&quot; program.
</em><br>
<em>&gt; &gt; The &quot;rewriting itsef&quot; is a ill-definition and the
</em><br>
<em>&gt; &gt; only thing is possible to achieve in this way is a reduction
</em><br>
<em>&gt; &gt; on a costant C.
</em><br>
<em>&gt; &gt; For example given an universal Turing machine accepting in
</em><br>
<em>&gt; &gt; input a program ( program without parameters) this turing
</em><br>
<em>&gt; &gt; machine executing the program can use new empty cells or
</em><br>
<em>&gt; &gt; rewrite a part or all the cells of the starting program.
</em><br>
<em>&gt; &gt; If this program rewrite itself partially or totally by C
</em><br>
<em>&gt; &gt; cells the only advantage you can have is to use also this C
</em><br>
<em>&gt; &gt; cells in the elaboration.
</em><br>
<em>&gt; &gt; There is not substantially difference from program and
</em><br>
<em>&gt; &gt; data.
</em><br>
<em>&gt; &gt; The trick is that you can move the program in the costant C
</em><br>
<em>&gt; &gt; and this disappear asymptotically.
</em><br>
<em>&gt; &gt; &quot;Rewiting itself&quot; is only an illusion.
</em><br>
<em>&gt; &gt; A nice example is the Hanoy tower . In the recursive
</em><br>
<em>&gt; &gt; program solving this problem you can watch at the stack and
</em><br>
<em>&gt; &gt; you can think to it as a program with the istructions to
</em><br>
<em>&gt; &gt; move the stones and this programs change! The trick is that
</em><br>
<em>&gt; &gt; you are watching the wrong program!
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Denis.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; --- On Sun, 9/14/08, Matt Mahoney
</em><br>
<em>&gt; &gt; &lt;<a href="mailto:matmahoney@yahoo.com?Subject=Re:%20[sl4]%20A%20model%20of%20RSI">matmahoney@yahoo.com</a>&gt; wrote:
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; &gt; From: Matt Mahoney &lt;<a href="mailto:matmahoney@yahoo.com?Subject=Re:%20[sl4]%20A%20model%20of%20RSI">matmahoney@yahoo.com</a>&gt;
</em><br>
<em>&gt; &gt; &gt; Subject: [sl4] A model of RSI
</em><br>
<em>&gt; &gt; &gt; To: &quot;sl4&quot; &lt;<a href="mailto:sl4@sl4.org?Subject=Re:%20[sl4]%20A%20model%20of%20RSI">sl4@sl4.org</a>&gt;
</em><br>
<em>&gt; &gt; &gt; Date: Sunday, September 14, 2008, 7:16 PM
</em><br>
<em>&gt; &gt; &gt; I have written a (rather trivial) recursively self
</em><br>
<em>&gt; &gt; improving
</em><br>
<em>&gt; &gt; &gt; program, along with a draft of a paper that tries to
</em><br>
<em>&gt; &gt; give a
</em><br>
<em>&gt; &gt; &gt; reasonable but rigorous definition of RSI. Any
</em><br>
<em>&gt; &gt; comments are
</em><br>
<em>&gt; &gt; &gt; appreciated.
</em><br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt; <a href="http://www.mattmahoney.net/rsi.pdf">http://www.mattmahoney.net/rsi.pdf</a>
</em><br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt; -- Matt Mahoney, <a href="mailto:matmahoney@yahoo.com?Subject=Re:%20[sl4]%20A%20model%20of%20RSI">matmahoney@yahoo.com</a>
</em><br>
<em>&gt;
</em><br>
<p><p><p><pre>
-- 
&quot;No, no, you're not thinking; you're just being logical.&quot; — Niels Bohr
&quot;There are two kinds of people, those who finish what they start and so on.&quot;
— Robert Byrne
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="19346.html">Stuart Armstrong: "Re: [sl4] A model of RSI"</a>
<li><strong>Previous message:</strong> <a href="19344.html">Matt Mahoney: "Re: [sl4] A model of RSI"</a>
<li><strong>In reply to:</strong> <a href="19344.html">Matt Mahoney: "Re: [sl4] A model of RSI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="19346.html">Stuart Armstrong: "Re: [sl4] A model of RSI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#19345">[ date ]</a>
<a href="index.html#19345">[ thread ]</a>
<a href="subject.html#19345">[ subject ]</a>
<a href="author.html#19345">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:03 MDT
</em></small></p>
</body>
</html>
