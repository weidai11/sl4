<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: DGI Paper</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: DGI Paper">
<meta name="Date" content="2002-04-13">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: DGI Paper</h1>
<!-- received="Sat Apr 13 22:15:25 2002" -->
<!-- isoreceived="20020414041525" -->
<!-- sent="Sat, 13 Apr 2002 22:07:52 -0400" -->
<!-- isosent="20020414020752" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: DGI Paper" -->
<!-- id="3CB8E478.4512AEE7@pobox.com" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="LAEGJLOGJIOELPNIOOAJOEDFCGAA.ben@goertzel.org" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20DGI%20Paper"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Sat Apr 13 2002 - 20:07:52 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="3343.html">Eliezer S. Yudkowsky: "META: Politics on SL4"</a>
<li><strong>Previous message:</strong> <a href="3341.html">Ben Goertzel: "RE: FW: DGI Paper"</a>
<li><strong>In reply to:</strong> <a href="3341.html">Ben Goertzel: "RE: FW: DGI Paper"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3344.html">Ben Goertzel: "RE: DGI Paper"</a>
<li><strong>Reply:</strong> <a href="3344.html">Ben Goertzel: "RE: DGI Paper"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3342">[ date ]</a>
<a href="index.html#3342">[ thread ]</a>
<a href="subject.html#3342">[ subject ]</a>
<a href="author.html#3342">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Ben Goertzel wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; By a &quot;reflective percept&quot; you mean a perception of something inside the mind
</em><br>
<em>&gt; rather than something in the external world?
</em><br>
<p>Yes - a cognitive event that can be, at the least, perceived; is often
<br>
visualizable as reflective imagery; and is sometimes even taken as an
<br>
action.
<br>
<p><em>&gt; &gt; &quot;Differential operator&quot; is abstract but that doesn't mean it's
</em><br>
<em>&gt; &gt; non-perceptual.  It means that its important perceptual correlates are
</em><br>
<em>&gt; &gt; abstract perceptual models and realtime skills in abstract
</em><br>
<em>&gt; &gt; models,
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I don't think I understand your use of the terms &quot;percept&quot; and &quot;perception&quot;?
</em><br>
<em>&gt; Could you tell me how you define these things?
</em><br>
<em>&gt; You seem to be using them much more broadly than me, which may the the
</em><br>
<em>&gt; source of much of my confusion.
</em><br>
<p>Recently (I'm not sure if I was doing this during the whole of the DGI
<br>
paper) I've been trying to restrict &quot;sensory&quot; to information produced by
<br>
environmental sense organs.  However, there are other perceptions than
<br>
this.  Imaginative imagery exists within the same working memory that
<br>
sensory information flows into, but it's produced by a different source. 
<br>
Abstract imagery might involve tracking &quot;objects&quot;, which can be very
<br>
high-level features of a sensory modality, but can also be features of no
<br>
sensory modality at all.  Even abstract concepts usually tend to be
<br>
associated with sensory percepts of one kind or another, such as
<br>
&quot;differentiation&quot; and the symbol &quot;d/dx&quot; or a visual image of a tangent to a
<br>
curve, but the *relevant* behaviors of abstract imagery are usually
<br>
interactions with other abstract objects and abstract properties, as opposed
<br>
to sensory behaviors of the kind tracked by sensory modalities proper -
<br>
although often these abstract behaviors can map onto sensory behaviors;
<br>
hence metaphor.
<br>
<p><em>&gt; Sure, but when one comes up with a NEW mathematical concept, sometimes it is
</em><br>
<em>&gt; not associated with ANY visual, auditory or otherwise &quot;imagistic&quot; stuff.
</em><br>
<em>&gt; It's purely a new math concept, which then has to be, through great labor,
</em><br>
<em>&gt; associated with appropriate symbols, pictures, names, or what have you.
</em><br>
<p>Right - but it's associated with the behaviors, in abstract imagery, of
<br>
other math concepts.  That's why you can't discover complex math concepts
<br>
without knowing simple math concepts; the complex math concepts are
<br>
abstracted from the abstract imagery for complex behaviors or complex
<br>
relations of simple math concepts.  But there is still imagery.  It is not
<br>
purely conceptual; one is imagining objects that are abstract objects
<br>
instead of sensory objects, and imagining properties that are abstract
<br>
properties instead of sensory properties, but there is still imagery there. 
<br>
It can be mapped onto the visual imagery of the blackboard and so on.
<br>
<p>Be it noted that this is a somewhat unusual hypothesis about the mind, in
<br>
which &quot;propositional&quot; cognition is a simplified special case of mental
<br>
imagery.  Abstract imagery uses non-depictive, often cross-modal layers that
<br>
are nonetheless connected by the detector/controller flow to the depictive
<br>
layers of mental imagery.  For example, consider the rats who were trained
<br>
to press lever A on seeing two flashes *or* hearing two sounds, and trained
<br>
to press lever B on seeing four flashes *or* hearing four sounds, who
<br>
spontaneously pressed lever B on seeing two flashes *and* hearing two
<br>
sounds.  I would explain this by reference to an Accumulator Model that is
<br>
smoothly extracted from depictive sensory perceptions, but which leaves
<br>
behind the &quot;topographic&quot; structure of those sensory modalities, and hence
<br>
can be cross-modality.  The Accumulator Model might even be &quot;depictive&quot; in
<br>
the sense of having a quantitative scale that is mapped to a linear stretch
<br>
of rat neurons, but it's not &quot;depictive&quot; in a way that topographically maps
<br>
to the sensory imagery.  For this reason, the rats' Accumulator Model can be
<br>
cross-modality.  I suspect that &quot;objects&quot; and &quot;properties&quot; within abstract
<br>
imagery may exist at a similarly high, cross-modality level - while still
<br>
being part of the overall modality system, permitting analogic mappings and
<br>
so on, and being smoothly connected to depictive sensory workspaces.
<br>
<p><em>&gt; &gt; Far as I know, they're all perceptual in the end.  It's just that the
</em><br>
<em>&gt; &gt; perceptual idiom - modalities, including feature structure,
</em><br>
<em>&gt; &gt; detector/controller structure, and occasionally realtime motor structure -
</em><br>
<em>&gt; &gt; extends far beyond things like vision and sound, to include
</em><br>
<em>&gt; &gt; internal reality
</em><br>
<em>&gt; &gt; as well.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; This is getting to the crux of my issue, I think.  You define &quot;perception&quot;
</em><br>
<em>&gt; as a kind of abstract structure/process, but in the paper I don't think it's
</em><br>
<em>&gt; entirely clear that this is how you're defining &quot;perception&quot;.  At least it
</em><br>
<em>&gt; wasn't that clear to me.  I generally think of perception as having to do
</em><br>
<em>&gt; with the processing of stimuli from the external world.
</em><br>
<p>Maybe I should put in a paragraph somewhere about &quot;sensory perception&quot; as a
<br>
special case of &quot;perception&quot;.
<br>
<p><em>&gt; Based on your very broad definition of perception, I'm not sure how to
</em><br>
<em>&gt; distinguish it from cognition.  I guess in your view perception serves
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 1) to process external-world data
</em><br>
<em>&gt; 2) as one among many cognitive structures/processes
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I don't think this is the standard use of the term &quot;perception&quot;, though
</em><br>
<em>&gt; there's nothing particularly wrong with it once it's understood.
</em><br>
<p>Perception is a very broad part of the mind - hence the &quot;modality level of
<br>
organization&quot; - and virtually everything that goes on inside the mind is
<br>
going to involve percepts/imagery in one way or another.  It won't all be
<br>
sensory imagery, however.  Senses and sensory imagery are a big chunk of the
<br>
modality level of organization, but they are not - quite - a level of
<br>
organization in themselves.
<br>
<p><em>&gt; I'm still not sure however that a new abstract math concept that I conceive
</em><br>
<em>&gt; in the bowels of my unconscious is &quot;perceptual in the end.&quot;  I think that
</em><br>
<em>&gt; its conception may in some cases NOT involve feature structures and
</em><br>
<em>&gt; detector/controller structures.  A new math concept may arise thru
</em><br>
<em>&gt; combinatory &amp; inferential operations on existing math concepts, without any
</em><br>
<em>&gt; of the perceptual/motor hierarchy-type structures you're describing.
</em><br>
<p>I think that human concepts don't come from mixing together the internal
<br>
representations of other concepts.  I think that's an AI idiom which is not
<br>
reflected in the human mind.  Humans may be capable of faceting concepts and
<br>
putting the facets together in new ways, like &quot;an object that smells like
<br>
coffee and tastes like chocolate&quot;, but this is (I think) taking apart the
<br>
concepts into kernels, not mixing the kernel representations together.
<br>
<p>Now it may perhaps be quite useful to open up concepts and play with their
<br>
internals!  I'm just saying that I don't think humans do it that way and I
<br>
don't think an AI should start off doing it that way.  I think it needs to
<br>
happen through the modality level of organization, not through the internal
<br>
representations of concepts.
<br>
<p><em>&gt; Math concepts are not the only example of this, of course, they're just a
</em><br>
<em>&gt; particularly clear example because of their highly abstract nature.
</em><br>
<p>Math concepts are *abstract* but not *non-perceptual*.  Perceiving yourself
<br>
manipulating mathematical objects is still perceiving, and you can
<br>
generalize a concept kernel over it.
<br>
<p><em>&gt; The key point is still, however, whether by &quot;perceptual modalities&quot; you mean
</em><br>
<em>&gt; modalities for sensing the external world, or something more abstract.
</em><br>
<p>I am referring to the superclass that contains &quot;sensory modalities&quot; but also
<br>
other things.
<br>
<p><em>&gt; I don't think that a new math concept i cook up necessarily has anything to
</em><br>
<em>&gt; do with imagery derived from any of the external-world senses.  Of course
</em><br>
<em>&gt; connections with sensorimotor domains can be CREATED, and must be for
</em><br>
<em>&gt; communication purposes.  But this may not be the case for AI's, which will
</em><br>
<em>&gt; be able to communicate by direct exchange of mindstuff rather than via
</em><br>
<em>&gt; structuring physicalistic actions &amp; sensations.
</em><br>
<p>The new math concept has plenty to do with imagery, it's just not sensory
<br>
imagery.
<br>
<p><em>&gt; &gt; I think some thoughts rely on reflective imagery or imagery which is not
</em><br>
<em>&gt; &gt; visualized all the way down to the sensory level.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Again this same language.  You're talking about some kind of &quot;visualizing&quot;
</em><br>
<em>&gt; at a non-sensory level.  I'm not sure what you mean by &quot;visualizing&quot; then.
</em><br>
<p>I mean creating mental imagery within a perceptual workspace that doesn't
<br>
flow all the way down to the visual or auditory modalities - although of
<br>
course a non-deaf human will almost always activate the auditory modalities
<br>
because our symbol tags are auditory.
<br>
<p><em>&gt; &gt; &quot;Smooth&quot; in fitness landscapes means that similar things are separated by
</em><br>
<em>&gt; &gt; short distances, and especially that incremental improvements are short
</em><br>
<em>&gt; &gt; distances.  In the case of a modality smoothing a raw scene, you can think
</em><br>
<em>&gt; &gt; of distance as being the distance between feature detectors instead of the
</em><br>
<em>&gt; &gt; distance between raw pixels, or &quot;distance&quot; as being inversely proportional
</em><br>
<em>&gt; &gt; to the probability of that step being taken within the system.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; This is just a terminology point, but I still think that your terminology is
</em><br>
<em>&gt; not the standard one.
</em><br>
<p>Quite possibly.  &quot;Smoothed fitness landscapes&quot; or &quot;smoother fitness
<br>
landscapes&quot; might be better.  &quot;Rugged fitness landscapes&quot; or &quot;fractal
<br>
fitness landscapes&quot; might be more mathematically accurate, but to someone
<br>
who doesn't know the math, it says exactly the opposite of what I want to
<br>
say!  Regardless of whether the landscapes are rugged or fractal in an
<br>
absolute sense, it is their smoothness that is salient in DGI's discussion.
<br>
<p>Maybe &quot;tractable fitness landscapes&quot;?  Got any suggestions?
<br>
<p><em>&gt; I still believe that, in the standard terminology, a fitness landscape that
</em><br>
<em>&gt; has local minima and maxima at all perceivable scales, is not &quot;smooth&quot; in
</em><br>
<em>&gt; standard usage.  It's fractal.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; The processing done in visual &amp; auditory cortex often resembles
</em><br>
<em>&gt; windowed-fourier or wavelet transforms, and this does result in a kind of
</em><br>
<em>&gt; smoothing in that hi-frequency components are omitted.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Anyway it would be good if you just clarified in the text what you meant by
</em><br>
<em>&gt; &quot;smooth&quot; -- it's certainly no big deal.
</em><br>
<p>I'll add it to the list.  In fact, I'll start keeping track of the list
<br>
instead of trying to keep it in my head.  (No guarantees about whether I'll
<br>
find the time, though; like I said I'm already over time-budget.)
<br>
<p><em>&gt; &gt; The Net can't help you here.  You can't have a modality with a
</em><br>
<em>&gt; &gt; computationally tractable feature structure unless your target environment
</em><br>
<em>&gt; &gt; *has* that kind of structure to begin with.  If you're going to put a baby
</em><br>
<em>&gt; &gt; AI in a rich environment, the richness has to be the kind that the baby AI
</em><br>
<em>&gt; &gt; can learn to see incrementally.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I don't understand why you think a baby AI can't learn to see the Net
</em><br>
<em>&gt; incrementally.
</em><br>
<p>It doesn't have a tractable fitness landscape.  No feature structure to
<br>
speak of.  No way to build up complex concepts from simple concepts.  It's
<br>
all complexity in a form that's meant to be perceived by other humans. 
<br>
Steven Harnad once compared the symbol grounding problem to trying to learn
<br>
Chinese as a first language using a Chinese-Chinese dictionary; if you're
<br>
blind and deaf then reading Chinese webpages won't help.  Strip away all the
<br>
semantic aspects of the Web and I don't quite see how the remaining
<br>
perceptible structure is a good environment in which to practice thinking -
<br>
a lot of directory and link structure, but that isn't a significant amount
<br>
of complexity as feature structures go.  Likewise for motor correlations
<br>
between HTTP requests and returned pages, and correlations between recurring
<br>
opaque Chinese symbols.  The tractable part is too simple to be useful and
<br>
the useful part is too complex to be tractable.
<br>
<p><em>&gt; &gt; What I mean is that noticing a perceptual cue that all the
</em><br>
<em>&gt; &gt; billiards in the
</em><br>
<em>&gt; &gt; &quot;key&quot; group are red, and that all the billiards in the &quot;non-key&quot; group are
</em><br>
<em>&gt; &gt; not red, is not the same as verifying that this is actually the case.  The
</em><br>
<em>&gt; &gt; cognitive process that initially delivers the perceptual cue, the
</em><br>
<em>&gt; &gt; suggestion
</em><br>
<em>&gt; &gt; saying &quot;Hey, check this out and see if it's true&quot;, may not always
</em><br>
<em>&gt; &gt; be the one
</em><br>
<em>&gt; &gt; that does the verification.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; So the verification is just done by more careful study of the same perceived
</em><br>
<em>&gt; scene, in this case?
</em><br>
<p>In this case, yeah.  The key point is that the cueing process can be simpler
<br>
and sloppier and even of an entirely different computational nature than the
<br>
process that goes through and verifies the initial suggestion.
<br>
<p><em>&gt; &gt; &gt; Complex concepts are certainly “invented” as well, under the normal
</em><br>
<em>&gt; &gt; &gt; definition of “invention.” …
</em><br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt; The concept of a pseudoinverse of a matrix was invented by Moore and
</em><br>
<em>&gt; &gt; &gt; Penrose, not learned by them.  I learned it from a textbook.
</em><br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt; The concept of &quot;Singularity&quot; was invented as well...
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Well, you can learn a concept from the thoughts that you invent -
</em><br>
<em>&gt; &gt; generalize
</em><br>
<em>&gt; &gt; a kernel over the reflective perceptual correlates of the
</em><br>
<em>&gt; &gt; thoughts.  But the
</em><br>
<em>&gt; &gt; concept-creating cognitive process will still reify (&quot;learn&quot;) a
</em><br>
<em>&gt; &gt; perception,
</em><br>
<em>&gt; &gt; and the deliberative thought process that created the abstract/reflective
</em><br>
<em>&gt; &gt; perceptions being reified will still be inventive.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I don't understand this.  If I create a silly concept right now, such as,
</em><br>
<em>&gt; say,
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &quot;Differential functions on [-5,5] whose third derivative is confined to the
</em><br>
<em>&gt; interval [0,1]&quot;
</em><br>
<p>This isn't much of a concept until it has a name.  Let's call a function
<br>
like this a &quot;dodomorphic fizzbin&quot;.
<br>
<p><em>&gt; then how is this concept LEARNED?  I didn't learn this, I just INVENTED it.
</em><br>
<p>You learned it by inventing it.  The invention process took place on the
<br>
deliberative level of organization.  The learning process took place on the
<br>
concept level of organization and it happened after the invention.  You
<br>
created the mental imagery and then attached it to a concept.  These things
<br>
happen one after the other but they are still different cognitive processes
<br>
taking place on different levels of organization.
<br>
<p><em>&gt; Evolutionary &amp; hypothetically-inferential combination of existing concepts &amp;
</em><br>
<em>&gt; parts thereof into new ones, guided by detected associations between
</em><br>
<em>&gt; concepts.  With a complex dynamic of attention allocation guiding the
</em><br>
<em>&gt; control of the process.
</em><br>
<p>I would have to say no to this one, at least as an idiom for human
<br>
intelligence.  There's a repertoire of background generalization processes
<br>
but they act on current imagery (generalized perceptual imagery), not the
<br>
representations of stored concepts - as far as I know.  It might be a good
<br>
ability for AIs to have *in addition* to the levels-of-organization idiom,
<br>
but it can't stand on its own.
<br>
<p><em>&gt; &gt; No, you often have mental imagery that depicts ongoing cognition
</em><br>
<em>&gt; &gt; within more
</em><br>
<em>&gt; &gt; than one train of thought, and you switch around the focus of attention,
</em><br>
<em>&gt; &gt; which means that more than one deliberative track can coexist.  You still
</em><br>
<em>&gt; &gt; think only one thought at a time.  Or do you mean that you pronounce more
</em><br>
<em>&gt; &gt; than one mental sentence at a time?  You've got to keep the thought level
</em><br>
<em>&gt; &gt; and the deliberation level conceptually separate; I said &quot;one thought at a
</em><br>
<em>&gt; &gt; time&quot;, not &quot;one deliberation at a time&quot;.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I don't understand how you define &quot;thought&quot;, then.  Could you give me a
</em><br>
<em>&gt; clearer definition?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; And please don't use a variant of the &quot;there can only be one at a time&quot;
</em><br>
<em>&gt; restriction in the definition!  ;)
</em><br>
<p>Deliberation is embodied in the cyclic interaction of thoughts and mental
<br>
imagery.  If you have two separate pieces of goal imagery and switch your
<br>
focus of attention back and forth between them, they will attract thoughts
<br>
of two different kinds and you will be able to carry out two interlaced
<br>
tracks of deliberation.  (And of course humans represent goals in a much
<br>
more complicated way than just imagery, which also contributes to our having
<br>
several going at once.)  So it might be like:
<br>
<p>1:  &quot;I need to get this paper done.&quot;
<br>
2:  &quot;I sure want some ice cream right now.&quot;
<br>
3:  &quot;Section 3 needs a little work on the spelling.&quot;
<br>
4:  &quot;I've already had my quota of calories for the day.&quot;
<br>
5:  &quot;Maybe I should replace 'dodomorphic' with 'anhaxic plorm'.&quot;
<br>
6:  &quot;If I exercised for an extra hour next week, that would make up for it.&quot;
<br>
<p>If these thoughts are all (human idiom) mental sentences in the internal
<br>
narrative, I wouldn't expect them to be pronounced simultaneously by a deep
<br>
adult voice and a squeaky child voice.  Rather I would expect them to be
<br>
interlaced, even though {1, 3, 5} relate to one piece of open goal imagery
<br>
and {2, 4, 6} relates to a different piece of goal imagery.  So the
<br>
deliberative tracks {1, 3, 5} and {2, 4, 6} are simultaneous, but the
<br>
thoughts 1, 2, 3, 4, 5, 6 occur sequentially.
<br>
<p><em>&gt; So far as I know, the physiology of human consciousness indicates that
</em><br>
<em>&gt; humans can have multiple perceptual-cognitive-active loops of conscious
</em><br>
<em>&gt; awareness running at once.
</em><br>
<p>???
<br>
<p><em>&gt; I guess that if you count kinesthetic sensation as a sense, then all motor
</em><br>
<em>&gt; actions can be mapped into the domain of sensation and considered that way.
</em><br>
<em>&gt; In practice of course, these particular &quot;sensory mappings&quot; (that are really
</em><br>
<em>&gt; motor mappings ;) will have to be treated pretty differently than the other
</em><br>
<em>&gt; sensory mappings.
</em><br>
<p>If it's a static mapping, based on a (claimed) correspondence, it's a
<br>
&quot;sensory&quot; mapping.  (I know this is overloading 'sensory' in an entirely
<br>
different sense, dammit.  Maybe I should replace 'sensory' within SPDM. 
<br>
&quot;Correlative?&quot;  &quot;Correspondence?&quot;)
<br>
<p>--              --              --              --              -- 
<br>
Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a> 
<br>
Research Fellow, Singularity Institute for Artificial Intelligence
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3343.html">Eliezer S. Yudkowsky: "META: Politics on SL4"</a>
<li><strong>Previous message:</strong> <a href="3341.html">Ben Goertzel: "RE: FW: DGI Paper"</a>
<li><strong>In reply to:</strong> <a href="3341.html">Ben Goertzel: "RE: FW: DGI Paper"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3344.html">Ben Goertzel: "RE: DGI Paper"</a>
<li><strong>Reply:</strong> <a href="3344.html">Ben Goertzel: "RE: DGI Paper"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3342">[ date ]</a>
<a href="index.html#3342">[ thread ]</a>
<a href="subject.html#3342">[ subject ]</a>
<a href="author.html#3342">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:38 MDT
</em></small></p>
</body>
</html>
