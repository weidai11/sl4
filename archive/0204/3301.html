<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: PAPER: Levels of Organization in General Intelligence</title>
<meta name="Author" content="Ben Houston (ben@exocortex.org)">
<meta name="Subject" content="RE: PAPER: Levels of Organization in General Intelligence">
<meta name="Date" content="2002-04-08">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: PAPER: Levels of Organization in General Intelligence</h1>
<!-- received="Mon Apr 08 04:46:46 2002" -->
<!-- isoreceived="20020408104646" -->
<!-- sent="Mon, 8 Apr 2002 04:30:38 -0400" -->
<!-- isosent="20020408083038" -->
<!-- name="Ben Houston" -->
<!-- email="ben@exocortex.org" -->
<!-- subject="RE: PAPER: Levels of Organization in General Intelligence" -->
<!-- id="000001c1ded7$a95ca300$6601a8c0@exonode" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="3CB0B6AA.9E6AF108@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Houston (<a href="mailto:ben@exocortex.org?Subject=RE:%20PAPER:%20Levels%20of%20Organization%20in%20General%20Intelligence"><em>ben@exocortex.org</em></a>)<br>
<strong>Date:</strong> Mon Apr 08 2002 - 02:30:38 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="3302.html">Eugen Leitl: "RE: PAPER: Levels of Organization in General Intelligence"</a>
<li><strong>Previous message:</strong> <a href="3300.html">Eugen Leitl: "[silk] The Future of Artificial Intelligence (fwd)"</a>
<li><strong>In reply to:</strong> <a href="3296.html">Eliezer S. Yudkowsky: "PAPER: Levels of Organization in General Intelligence"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3302.html">Eugen Leitl: "RE: PAPER: Levels of Organization in General Intelligence"</a>
<li><strong>Reply:</strong> <a href="3302.html">Eugen Leitl: "RE: PAPER: Levels of Organization in General Intelligence"</a>
<li><strong>Reply:</strong> <a href="3309.html">Eliezer S. Yudkowsky: "Re: PAPER: Levels of Organization in General Intelligence"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3301">[ date ]</a>
<a href="index.html#3301">[ thread ]</a>
<a href="subject.html#3301">[ subject ]</a>
<a href="author.html#3301">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Random initial comments....  Quotes from the paper are contained between
<br>
<em>&gt;&gt;&gt; &lt;&lt;&lt; demarcations. 
</em><br>
<p><em>&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;
</em><br>
Parallelism on the hardware level is currently supported by symmetric
<br>
multiprocessing chip architectures [Hwang98], NOW
<br>
(network-of-workstations) clustering [Anderson95] and Beowulf clustering
<br>
[Becker95], and message-passing APIs such as PVM [Geist93] and MPI
<br>
[Gropp94].  However, software-level parallelism is not handled well by
<br>
present-day languages and is therefore likely to present one of the
<br>
greatest challenges.
<br>
&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
<br>
<p>I've seen some truly amazing things done in the computational
<br>
pharmacology field dealing with cheap, but massive parallelization.
<br>
Basically, a lot of short cuts are available in the parallelization of
<br>
an algorithm once you've solidified it.  In order words making a
<br>
parallel problem solving is difficult and cost in the general case but
<br>
in a specific case it can be quite cheap.  The field of computational
<br>
pharmacology is working with special purpose multi-teraflop machines
<br>
that cost less than $1,000,000 US for a year or so now.
<br>
<p><em>&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;
</em><br>
Even if software parallelism were well-supported, AI developers will
<br>
still need to spend time explicitly thinking on how to parallelize
<br>
cognitive processes - human cognition may be massively parallel on the
<br>
lower levels, but the overall flow of cognition is still serial.
<br>
&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
<br>
<p>Cognition, in my opinion, is quite parallel at all levels.  There are,
<br>
in my understanding, only a few bottlenecks in the brain that forces
<br>
things to become serial.  An obvious example would be the serial nature
<br>
of linguistic output.
<br>
<p><em>&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;
</em><br>
We know it is possible to evolve a general intelligence that runs on a
<br>
hundred trillion synapses with characteristic limiting speeds of
<br>
approximately 200 spikes per second.
<br>
&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
<br>
<p>200 spikes/sec is probably the median for the brain.  Some neurons I've
<br>
studied in my courses have upper limits around 1000 spikes/sec.
<br>
<p><em>&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;
</em><br>
[Sandberg99] describes a quantity S that translates to the wait time, in
<br>
clock cycles, between different parts of a cognitive system - the
<br>
minimum time it could take for a signal to travel between the most
<br>
distant parts of the system, measured in the system's clock ticks.  For
<br>
the human brain, S is on the rough order of 1 - in theory, at least.
<br>
&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
<br>
<p>Let's take for an example a sensory neuron in one's finger and a
<br>
alpha-motor neuron in one's thigh.  The sensory neuron, as we all know,
<br>
will synapse with another neuron in the spine.  That spinal neuron will
<br>
then project to the lower brain steam where it will synapse with some
<br>
neuron.  Thus it takes 2 neurons to get to the brain.  The alpha-motor
<br>
neuron, which will most likely begin in the spine, will receive input
<br>
from other spinal neuron(s) -- of which one is probably a projection
<br>
from the motor cortex or a lower motor region.  Thus there is at least a
<br>
2-neuron chain from the brain to a muscle.  This means that sensory to
<br>
motor neuron round trip is at least 4 neurons in length.
<br>
<p>Neglect the sensory and motor systems I believe that in the CNS 'S'
<br>
would be upwards of at least 5 as a result of the DAG-like arrangements
<br>
of the signal processing pathways -- ignoring backwards, regulatory
<br>
projections. 
<br>
&nbsp;
<br>
<em>&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;
</em><br>
Memory association may or may not use a &quot;compare&quot; operation (brute force
<br>
or otherwise) of current imagery against all stored memories, but it
<br>
seems likely that the brain uses a massively parallel algorithm at one
<br>
point or another of its operation; memory association is simply a
<br>
plausible candidate.
<br>
&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
<br>
<p>It seems plausible that the brain uses a resonance-like compare
<br>
function.  Basically, a match may be recognized when a neural assembly
<br>
finds its group-firing greatly facilitated as a result of the
<br>
presented/remembered stimulus.  Sort of like how a glass will vibrate
<br>
when exposed to its natural resonance frequency.
<br>
<p><em>&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;
</em><br>
The human brain's most fundamental limit is its speed.  Anything that
<br>
happens in less than a second perforce must use less than 200 sequential
<br>
operations, however massively parallelized.
<br>
&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
<br>
<p>Although the simple firing of neurons represents a lot of the
<br>
information that the brain is processing probably just as much
<br>
information is represented in the dynamic molecular mechanisms of each
<br>
cell.  Cells constantly change their gene expression on the order of
<br>
minutes.  On the order of seconds in any one neuron there are probably
<br>
dozens on interacting molecular signally cascades that are changing the
<br>
neuron's electrophysiological behavior.
<br>
<p><em>&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;
</em><br>
As mentioned earlier, primary visual cortex sends massive
<br>
corticothalamic feedback projections to the lateral geniculate nucleus
<br>
[Sherman86].  Corticocortical connections are also typically accompanied
<br>
by feedback projections of equal strength [Felleman91].  There is
<br>
currently no standard explanation for these feedback connections.
<br>
&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
<br>
<p>Actually, there is quite a collection of papers in PubMed discussing the
<br>
evidence that the corticothalamic feedback projections play a role in
<br>
image contrast control.
<br>
<p><em>&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;
</em><br>
DGI16 requires sensory modalities with feature controllers that are the
<br>
inverse complements of the feature detectors; this fits with the
<br>
existence of the feedback projections.  However, it should be noted that
<br>
this assertion is not part of contemporary neuroscience.  The existence
<br>
of feature controllers is allowed for, but not asserted, by current
<br>
theory; their existence is asserted, and required, by DGI.  (The
<br>
hypothesis that feedback projections play a role in mental imagery is
<br>
not limited to DGI; for example, [Kosslyn94] cites the existence of
<br>
corticocortical feedback projections as providing an underlying
<br>
mechanism for higher-level cognitive functions to control depictive
<br>
mental imagery.) 
<br>
&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
<br>
<p>It is an accepted fact that working memory, both verbal and spatial, is
<br>
maintained by mutual stimulation between the lateral prefrontal cortex
<br>
and certain posterior association areas:
<br>
<p>Postle BR, Stern CE, Rosen BR, Corkin S. 2000.  &quot;An fMRI investigation
<br>
of cortical contributions to spatial and nonspatial visual working
<br>
memory.&quot; Neuroimage. May;11(5 Pt 1):409-23.
<br>
<p>Diwadkar VA, Carpenter PA, Just MA. 2000. &quot;Collaborative activity
<br>
between parietal and dorso-lateral prefrontal cortex in dynamic spatial
<br>
working memory revealed by fMRI.&quot;
<br>
Neuroimage. Jul;12(1):85-99.
<br>
<p>SARNTHEIN J, et al.  1998.  &quot;Synchronization between prefrontal and
<br>
posterior association cortex during human working memory.&quot;  PNAS, Vol.
<br>
95, pp. 7092–7096.
<br>
<p><em>&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;
</em><br>
Concepts act as verbs, adjectives, and adverbs as well as nouns.
<br>
&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
<br>
<p>I'm not sure if you mentioned it but did you know that 'verbs' seems to
<br>
be stored in a different brain region that 'nouns'?  And that 'noun'
<br>
storage in the brain seems to be organized in a categorized spatial
<br>
manner?  Neat stuff eh?
<br>
<p><em>&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;
</em><br>
The thought level lies above the learned complexity of the concept
<br>
level.  Thoughts are structures of combinatorial concepts that alter
<br>
imagery within the workspace of sensory modalities.  Thoughts are the
<br>
disposable one-time structures implementing a non-recurrent mind in a
<br>
non-recurrent world.  Modalities are wired; concepts are learned;
<br>
thoughts are invented.
<br>
&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
<br>
<p>In your section on &quot;thought&quot; why don't you mention the cognitive
<br>
psychology construct of &quot;working memory&quot;?  You seem to describe its two
<br>
part structure perfectly: (1) phonological loop and (2) visuospatial
<br>
sketchpad.
<br>
<p>And at this point, I must stop since I have some things that I must
<br>
complete.
<br>
<p>Cheers,
<br>
-ben houston
<br>
4th Year Cognitive Science/Neuroscience
<br>
Carleton University, Ottawa, Canada
<br>
( <a href="mailto:ben@exocortex.org?Subject=RE:%20PAPER:%20Levels%20of%20Organization%20in%20General%20Intelligence">ben@exocortex.org</a> / 613-266-0637 )
<br>
  
<br>
<p><p><em>&gt; -----Original Message-----
</em><br>
<em>&gt; From: <a href="mailto:owner-sl4@sysopmind.com?Subject=RE:%20PAPER:%20Levels%20of%20Organization%20in%20General%20Intelligence">owner-sl4@sysopmind.com</a> [mailto:<a href="mailto:owner-sl4@sysopmind.com?Subject=RE:%20PAPER:%20Levels%20of%20Organization%20in%20General%20Intelligence">owner-sl4@sysopmind.com</a>] On
</em><br>
Behalf
<br>
<em>&gt; Of Eliezer S. Yudkowsky
</em><br>
<em>&gt; Sent: Sunday, April 07, 2002 5:14 PM
</em><br>
<em>&gt; To: <a href="mailto:sing@yahoogroups.com?Subject=RE:%20PAPER:%20Levels%20of%20Organization%20in%20General%20Intelligence">sing@yahoogroups.com</a>
</em><br>
<em>&gt; Cc: SL4
</em><br>
<em>&gt; Subject: PAPER: Levels of Organization in General Intelligence
</em><br>
<em>&gt; 
</em><br>
<em>&gt; A draft of the paper &quot;Levels of Organization in General Intelligence&quot;,
</em><br>
to
<br>
<em>&gt; appear in Ben Goertzel and Cassio Pennachin (eds.), &quot;Real AI: New
</em><br>
<em>&gt; Approaches
</em><br>
<em>&gt; to Artificial General Intelligence&quot;, is now available online.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; It has not been linked in to SIAI's main site or announced anywhere.
</em><br>
I
<br>
<em>&gt; should probably do that after I answer my accumulated email, do my
</em><br>
income
<br>
<em>&gt; tax returns, and get some sleep.  I probably shouldn't say anything
</em><br>
more
<br>
<em>&gt; until I have some idea of the audience's reactions.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; <a href="http://intelligence.org/DGI/">http://intelligence.org/DGI/</a>     (multi-file)
</em><br>
<em>&gt; <a href="http://intelligence.org/DGI.html">http://intelligence.org/DGI.html</a> (single file, 382K)
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Abstract:
</em><br>
<em>&gt; 
</em><br>
<em>&gt; LEVELS OF ORGANIZATION IN GENERAL INTELLIGENCE
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Part I discusses the conceptual foundations of general intelligence as
</em><br>
a
<br>
<em>&gt; discipline, orienting it within the Integrated Causal Model of Tooby
</em><br>
and
<br>
<em>&gt; Cosmides.  Part II constitutes the bulk of the paper and discusses the
</em><br>
<em>&gt; functional decomposition of general intelligence into a complex
</em><br>
<em>&gt; supersystem
</em><br>
<em>&gt; of interdependent internally specialized processes, and structures the
</em><br>
<em>&gt; description using five successive levels of functional organization:
</em><br>
<em>&gt; Code,
</em><br>
<em>&gt; sensory modalities, concepts, thoughts, and deliberation.  Part III
</em><br>
<em>&gt; discusses probable differences between humans and AIs and points out
</em><br>
<em>&gt; several
</em><br>
<em>&gt; fundamental advantages that minds-in-general potentially possess
</em><br>
relative
<br>
<em>&gt; to
</em><br>
<em>&gt; current evolved intelligences, especially with respect to recursive
</em><br>
<em>&gt; self-improvement.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; --              --              --              --              --
</em><br>
<em>&gt; Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a>
</em><br>
<em>&gt; Research Fellow, Singularity Institute for Artificial Intelligence
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3302.html">Eugen Leitl: "RE: PAPER: Levels of Organization in General Intelligence"</a>
<li><strong>Previous message:</strong> <a href="3300.html">Eugen Leitl: "[silk] The Future of Artificial Intelligence (fwd)"</a>
<li><strong>In reply to:</strong> <a href="3296.html">Eliezer S. Yudkowsky: "PAPER: Levels of Organization in General Intelligence"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3302.html">Eugen Leitl: "RE: PAPER: Levels of Organization in General Intelligence"</a>
<li><strong>Reply:</strong> <a href="3302.html">Eugen Leitl: "RE: PAPER: Levels of Organization in General Intelligence"</a>
<li><strong>Reply:</strong> <a href="3309.html">Eliezer S. Yudkowsky: "Re: PAPER: Levels of Organization in General Intelligence"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3301">[ date ]</a>
<a href="index.html#3301">[ thread ]</a>
<a href="subject.html#3301">[ subject ]</a>
<a href="author.html#3301">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:38 MDT
</em></small></p>
</body>
</html>
