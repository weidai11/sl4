<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Why I'm not more involved with academia</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="RE: Why I'm not more involved with academia">
<meta name="Date" content="2004-10-23">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Why I'm not more involved with academia</h1>
<!-- received="Sat Oct 23 09:18:13 2004" -->
<!-- isoreceived="20041023151813" -->
<!-- sent="Sat, 23 Oct 2004 11:18:15 -0400" -->
<!-- isosent="20041023151815" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="RE: Why I'm not more involved with academia" -->
<!-- id="JNEIJCJJHIEAILJBFHILMEPOCIAA.ben@goertzel.org" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="417A5643.5000301@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=RE:%20Why%20I'm%20not%20more%20involved%20with%20academia"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Sat Oct 23 2004 - 09:18:15 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="10079.html">Ben Goertzel: "RE: Why SIAI is a nonprofit"</a>
<li><strong>Previous message:</strong> <a href="10077.html">Giu1i0 Pri5c0: "Re: Why I donate to the SIAI"</a>
<li><strong>In reply to:</strong> <a href="10071.html">Eliezer Yudkowsky: "Why I'm not more involved with academia"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10080.html">Eliezer Yudkowsky: "Re: Why I'm not more involved with academia"</a>
<li><strong>Reply:</strong> <a href="10080.html">Eliezer Yudkowsky: "Re: Why I'm not more involved with academia"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10078">[ date ]</a>
<a href="index.html#10078">[ thread ]</a>
<a href="subject.html#10078">[ subject ]</a>
<a href="author.html#10078">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Eliezer,
<br>
<p>I don't really think this is an SL4-worthy topic [as the focus is your own
<br>
career and life rather than the Singularity and related themes], but I'll
<br>
make one remark.
<br>
<p>In fact, knowing you moderately well as I do, I think that getting a PhD and
<br>
becoming an academic would be a reasonably good choice for you.  Getting the
<br>
PhD would be fairly easy for you, and once you had it, you could get a job
<br>
as a professor, guaranteeing you a lifetime income, with fairly  minimal
<br>
duties beyond doing and publishing your research.  And, perhaps more
<br>
importantly, you having a PhD would make it significantly easier for SIAI to
<br>
raise money for your research.
<br>
<p>Personally, I benefited a lot from the research-time I obtained via being an
<br>
academic for 8 years; and in my business pursuits now, I'm taken more
<br>
seriously than I would be otherwise because I have a PhD.
<br>
<p>There's something to be said for boldly forging your own path in life, but
<br>
there's also some value to playing the games of the society you're embedded
<br>
within.
<br>
<p>-- Ben G
<br>
<p><em>&gt; -----Original Message-----
</em><br>
<em>&gt; From: <a href="mailto:owner-sl4@sl4.org?Subject=RE:%20Why%20I'm%20not%20more%20involved%20with%20academia">owner-sl4@sl4.org</a> [mailto:<a href="mailto:owner-sl4@sl4.org?Subject=RE:%20Why%20I'm%20not%20more%20involved%20with%20academia">owner-sl4@sl4.org</a>]On Behalf Of Eliezer
</em><br>
<em>&gt; Yudkowsky
</em><br>
<em>&gt; Sent: Saturday, October 23, 2004 9:02 AM
</em><br>
<em>&gt; To: <a href="mailto:sl4@sl4.org?Subject=RE:%20Why%20I'm%20not%20more%20involved%20with%20academia">sl4@sl4.org</a>
</em><br>
<em>&gt; Subject: Why I'm not more involved with academia
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; Jeff Medina wrote:
</em><br>
<em>&gt; &gt; Robin Lee Powell wrote: &quot;IIRC, Eliezer is not allowed to put Ph.D.
</em><br>
<em>&gt; &gt; after his name.  That pretty much rules out this avenue of approach.&quot;
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; That absolutely *does not* rule out this avenue of approach.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Correct.
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt; Many
</em><br>
<em>&gt; &gt; respected journals and conferences in the relevant areas are
</em><br>
<em>&gt; &gt; blind-reviewed (such that the academic credentials of the author of
</em><br>
<em>&gt; &gt; the paper is made irrelevant, because the author's identity &amp; other
</em><br>
<em>&gt; &gt; info is kept secret), and even among the many which are not quality
</em><br>
<em>&gt; &gt; submissions are never rejected or looked down upon simply due to the
</em><br>
<em>&gt; &gt; lack of a Ph.D. by the author.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Papers which are *not* blind-reviewed show a *decided* bias toward known,
</em><br>
<em>&gt; prestigious researchers and institutions.  That is *why* some
</em><br>
<em>&gt; journals are
</em><br>
<em>&gt; blind-reviewed.  Most aren't, and it doesn't help that other journals are
</em><br>
<em>&gt; blind-reviewed if the one you want to target isn't.  I've read studies
</em><br>
<em>&gt; assessing the bias, but though I googled on &quot;effectiveness of
</em><br>
<em>&gt; peer review&quot;
</em><br>
<em>&gt; I failed to track them down.  I did find other interesting material
</em><br>
<em>&gt; including, to pick an arbitrary example, a study by Rothwell and Martyn
</em><br>
<em>&gt; (2000) showing that peer review in two neuroscience journals was not
</em><br>
<em>&gt; reproducible; that is, agreement between reviewers is not significantly
</em><br>
<em>&gt; greater than chance.  My recollection is that this result is
</em><br>
<em>&gt; widespread in
</em><br>
<em>&gt; studies of this kind.  I include this tidbit by way of saying that
</em><br>
<em>&gt; experimental study of peer review has produced surprising and alarming
</em><br>
<em>&gt; results, so be sure to check out peer-reviewed studies of peer review
</em><br>
<em>&gt; before praising its effectiveness.
</em><br>
<em>&gt;
</em><br>
<em>&gt; (Rothwell PM, Martyn CN. Reproducibility of peer review in clinical
</em><br>
<em>&gt; neuroscience. Is agreement between reviewers any greater than would be
</em><br>
<em>&gt; expected by chance alone? Brain 2000;123:1964-9.)
</em><br>
<em>&gt;
</em><br>
<em>&gt; This has nothing to do with the reason I don't write additional academic
</em><br>
<em>&gt; papers.  I just thought I'd mention it.
</em><br>
<em>&gt;
</em><br>
<em>&gt; **
</em><br>
<em>&gt;
</em><br>
<em>&gt; First, you'll note that I say &quot;write additional papers&quot;.  I allocated one
</em><br>
<em>&gt; month in early 2002 to write &quot;Levels of Organization in General
</em><br>
<em>&gt; Intelligence&quot; (LOGI) in the best academic style I could manage.  It
</em><br>
<em>&gt; actually took four months.  Since then the draft has been online at
</em><br>
<em>&gt; <a href="http://intelligence.org/LOGI/">http://intelligence.org/LOGI/</a>.  In 2005 this paper will finally appear in
</em><br>
<em>&gt; &quot;Artificial General Intelligence&quot;, eds. Goertzel and Pennachin, to be
</em><br>
<em>&gt; published by Springer-Verlag in 2005.  (The three-year delay was for the
</em><br>
<em>&gt; entire book, not my own paper; *I* turned in my homework on time.)
</em><br>
<em>&gt;
</em><br>
<em>&gt; The fact that none of the people plaguing me to write papers have even
</em><br>
<em>&gt; *noticed* &quot;Levels of Organization in General Intelligence&quot;, speaking
</em><br>
<em>&gt; instead as if I haven't written *any* papers, is indeed related to the
</em><br>
<em>&gt; reason I am not more involved with academia.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I've come a long way over the eight years since 1996.  People said to me:
</em><br>
<em>&gt; Write up your ideas about AI in a web page.  In 1998 I did.  Then new
</em><br>
<em>&gt; people came along and they said:  You'll never get anywhere with this, no
</em><br>
<em>&gt; one will be interested enough to pay you to do this.  In 2000, thanks to
</em><br>
<em>&gt; Brian Atkins, the Singularity Institute started up.  Possibly that
</em><br>
<em>&gt; impressed a few people who never thought I'd get that far.  Then
</em><br>
<em>&gt; new people
</em><br>
<em>&gt; came along, to whom Eliezer had *always been* a part of the Singularity
</em><br>
<em>&gt; Institute, so it wasn't impressive, and they said:  No one will ever pay
</em><br>
<em>&gt; attention to you unless you do as we say and write some kind of paper
</em><br>
<em>&gt; targeted at academia and get it published.  In 2002 I did.  I
</em><br>
<em>&gt; didn't expect
</em><br>
<em>&gt; anyone to notice, and no one did, but the effort of writing the
</em><br>
<em>&gt; LOGI paper
</em><br>
<em>&gt; served to help me unify my ideas and force me to read relevant literature
</em><br>
<em>&gt; and therefore I account it a partial success.  And lo, the people said:
</em><br>
<em>&gt; What you really need, Eliezer, is to write some kind of paper targeted at
</em><br>
<em>&gt; academia.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Someone always thinks there's just one more thing you need to do.  *That*
</em><br>
<em>&gt; never changes, no matter how many times you fulfill the request.
</em><br>
<em>&gt; They just
</em><br>
<em>&gt; find something else for you to do.  Often it's something you've already
</em><br>
<em>&gt; done.  I wasn't puzzled by this.  I expected it.  Thus the particular
</em><br>
<em>&gt; things that I did were selected strictly on the basis of their needing
</em><br>
<em>&gt; doing, rather than to one-up naysayers.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Case in point:  Dr. Eric Drexler and _Nanosystems_.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Before:  Eric Drexler has no PhD and hasn't written up his ideas in great
</em><br>
<em>&gt; gory technical detail.  People tell him:  Eric, no one will pay attention
</em><br>
<em>&gt; to you if you don't have a PhD.  People tell him:  Eric, you need
</em><br>
<em>&gt; to write
</em><br>
<em>&gt; up your technical ideas in great gory detail in a way that a wide
</em><br>
<em>&gt; audience
</em><br>
<em>&gt; can understand.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Eric spends six years writing _Nanosystems_ and making it presentable to
</em><br>
<em>&gt; any technical reader without demanding a specific background in
</em><br>
<em>&gt; chemistry,
</em><br>
<em>&gt; physics, or computer science.  Eric defends _Nanosystems_ as his
</em><br>
<em>&gt; thesis and
</em><br>
<em>&gt; receives the world's first PhD in nanotechnology from MIT.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Afterward:  None of the naysayers read _Nanosystems_ or even mention it
</em><br>
<em>&gt; exists.  No one pays any more attention to Drexler than before.
</em><br>
<em>&gt; They just
</em><br>
<em>&gt; shift their criterion to something else Eric hasn't done yet.  Often they
</em><br>
<em>&gt; indignantly proclaim that Drexler hasn't given any technical presentation
</em><br>
<em>&gt; of his ideas - complete indifference to the work already
</em><br>
<em>&gt; accomplished.  The
</em><br>
<em>&gt; same people who liked Drexler before still like him.  The kind of people
</em><br>
<em>&gt; who objected to Drexler before find something different to which
</em><br>
<em>&gt; to object.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I suspect those who objected to nanotechnology did not say:
</em><br>
<em>&gt; &quot;Hm... I have
</em><br>
<em>&gt; no idea whether I like this or not... but wait!  Drexler doesn't have a
</em><br>
<em>&gt; PhD!  Okay, now I've decided that nanotechnology is impossible
</em><br>
<em>&gt; and Drexler
</em><br>
<em>&gt; is scaring our children.&quot;  The causal sequence of events is more like,
</em><br>
<em>&gt; &quot;Eek!  Too weird!  Hm, it seems that I disbelieve in nanotechnology.  I
</em><br>
<em>&gt; wonder why I disbelieve in nanotechnology?  (Searches for
</em><br>
<em>&gt; reason.)  It must
</em><br>
<em>&gt; be because Drexler doesn't have a PhD, hey, yeah, that's it.&quot;  After
</em><br>
<em>&gt; Drexler got a PhD, exactly the same process took place, only the
</em><br>
<em>&gt; rationalization search terminated elsewhere.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Drexler has a personality far better suited to academia than I'll
</em><br>
<em>&gt; ever be.
</em><br>
<em>&gt;   He's humble.  He did everything by the book, the way he was
</em><br>
<em>&gt; supposed to.
</em><br>
<em>&gt;   Academia... to put it bluntly, they spit in his face.  And
</em><br>
<em>&gt; Drexler had a
</em><br>
<em>&gt; vastly easier problem to explain, in a field with all the underlying
</em><br>
<em>&gt; physical equations established and agreed upon.  If Drexler
</em><br>
<em>&gt; didn't make it
</em><br>
<em>&gt; in academia there's no chance in hell that I could do so.  Friendly AI
</em><br>
<em>&gt; would be two orders of magnitude harder to sell to academia than
</em><br>
<em>&gt; molecular
</em><br>
<em>&gt; nanotechnology.  I pointed out that last part to Drexler, by the way; he
</em><br>
<em>&gt; agreed.  And come to think, while he didn't say a word to me against
</em><br>
<em>&gt; academia or the academic system, Dr. Eric Drexler is *not* on the list of
</em><br>
<em>&gt; people whose advice to me included getting a PhD.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I don't want to sound like I'm criticizing Drexler's
</em><br>
<em>&gt; intelligence.  Drexler
</em><br>
<em>&gt; did not have Drexler's case to warn him.  Drexler's choices were
</em><br>
<em>&gt; different;
</em><br>
<em>&gt; he may have had nothing better to try than getting a PhD and spending six
</em><br>
<em>&gt; years writing a technical book.
</em><br>
<em>&gt;
</em><br>
<em>&gt; But people seem to be absurdly optimistic about how easy it is for the
</em><br>
<em>&gt; actors on stage to carry out the helpful advice shouted from the
</em><br>
<em>&gt; audience.
</em><br>
<em>&gt;   Then again, as plenty of studies show, people are also absurdly
</em><br>
<em>&gt; optimistic about the course of their own lives - except for the severely
</em><br>
<em>&gt; depressed, who are sometimes properly calibrated with respect to
</em><br>
<em>&gt; outcomes,
</em><br>
<em>&gt; a phenomenon known as &quot;depressive realism&quot;.  (I am not making this up.)
</em><br>
<em>&gt; Part of the reason why people are absurdly optimistic is that they think:
</em><br>
<em>&gt; I'll just do X, and then everything will be all right!  Not:  I'll try to
</em><br>
<em>&gt; do X, it will take four times as long as I expect, I'll probably
</em><br>
<em>&gt; fail, and
</em><br>
<em>&gt; even if I succeed, only one in ten successes of this kind have as
</em><br>
<em>&gt; great an
</em><br>
<em>&gt; impact as the one I pleasantly imagined.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I remember meeting Chris Phoenix of CRN at a Foresight Gathering,
</em><br>
<em>&gt; and Chris
</em><br>
<em>&gt; Phoenix spoke optimistically of the day when molecular manufacturing is
</em><br>
<em>&gt; proved possible, and all the naysayers have to admit it... and I said:
</em><br>
<em>&gt; &quot;Yes, Chris, we can look forward to the fine day when the naysayers are
</em><br>
<em>&gt; presented with a working example of mechanosynthesis, and they
</em><br>
<em>&gt; are finally
</em><br>
<em>&gt; forced to stand up and say, in unison: 'Oh, but that isn't *really*
</em><br>
<em>&gt; nanotechnology.'&quot;
</em><br>
<em>&gt;
</em><br>
<em>&gt; Did I get a Ph.D., nothing would change.  I'd just hear: oh, but
</em><br>
<em>&gt; you aren't
</em><br>
<em>&gt; an eminent scientist in the field, go write more papers.
</em><br>
<em>&gt;
</em><br>
<em>&gt; If I were the sort of person who chased all over the map - starting
</em><br>
<em>&gt; companies, getting PhDs, whatever - then I wouldn't be here in the first
</em><br>
<em>&gt; place.  My life would have happened to me while I was making other plans.
</em><br>
<em>&gt; Antoine de Saint-Exupéry:  &quot;Perfection is achieved, not when there is
</em><br>
<em>&gt; nothing left to add, but when there is nothing left to take
</em><br>
<em>&gt; away.&quot;  People
</em><br>
<em>&gt; overestimate conjunctive probabilities and underestimate disjunctive
</em><br>
<em>&gt; probabilities; they overestimate the chance of many things going right in
</em><br>
<em>&gt; sequence, underestimate the probability of a single thing going
</em><br>
<em>&gt; wrong.  The
</em><br>
<em>&gt; way to success is to remove everything from the plan that doesn't
</em><br>
<em>&gt; absolutely *have* to be there.  The way to have any chance at all of
</em><br>
<em>&gt; finishing on time is to do nothing that is not absolutely necessary.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Is being a part of academia absolutely necessary to success?  I
</em><br>
<em>&gt; don't think
</em><br>
<em>&gt; so.  No one's told me to get a PhD in something because in-depth
</em><br>
<em>&gt; technical
</em><br>
<em>&gt; mastery of that subject is absolutely necessary to the creation
</em><br>
<em>&gt; of AI, and
</em><br>
<em>&gt; yet that is *supposed* to be what PhDs are about.  No one's said a word
</em><br>
<em>&gt; about learning or knowledge.  It's all about the impressiveness of some
</em><br>
<em>&gt; letters after your name.  I know I'm far from the first person to
</em><br>
<em>&gt; point out
</em><br>
<em>&gt; the massive failure of the educational system, but it remains
</em><br>
<em>&gt; just as huge
</em><br>
<em>&gt; a problem and just as horribly awry.  The failure doesn't go away just
</em><br>
<em>&gt; because someone has pointed it out before.
</em><br>
<em>&gt;
</em><br>
<em>&gt; To tackle AI I've had to learn, at one time or another, evolutionary
</em><br>
<em>&gt; psychology, evolutionary biology, population genetics, game theory,
</em><br>
<em>&gt; information theory, Bayesian probability theory, mathematical logic,
</em><br>
<em>&gt; functional neuroanatomy, computational neuroscience, anthropology,
</em><br>
<em>&gt; computing in single neurons, cognitive psychology, the cognitive
</em><br>
<em>&gt; psychology
</em><br>
<em>&gt; of categories, heuristics and biases, decision theory, visual neurology,
</em><br>
<em>&gt; linguistics, linear algebra, physics, category theory, and
</em><br>
<em>&gt; probably a dozen
</em><br>
<em>&gt; other fields I haven't thought of offhand.  Sometimes, as with
</em><br>
<em>&gt; evolutionary
</em><br>
<em>&gt; psychology, I know the field in enough depth to write papers in
</em><br>
<em>&gt; it.  Other
</em><br>
<em>&gt; times I know only the absolute barest embarassingly simple
</em><br>
<em>&gt; basics, as with
</em><br>
<em>&gt; category theory, which I picked up less than a month ago because I needed
</em><br>
<em>&gt; to read other papers written in the language of category theory.  But the
</em><br>
<em>&gt; point is that in academia, where crossbreeding two or three fields is
</em><br>
<em>&gt; considered daring and interdisciplinary, and where people have to achieve
</em><br>
<em>&gt; supreme depth in a single field in order to publish in its journals, that
</em><br>
<em>&gt; kind of broad background is pretty rare.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I'm a competent computer programmer with strong C++, Java, and
</em><br>
<em>&gt; Python, and
</em><br>
<em>&gt; I can read a dozen other programming languages.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I accumulated all that (except category theory) before I was twenty-five
</em><br>
<em>&gt; years old, which is still young enough to have revolutionary ideas.
</em><br>
<em>&gt;
</em><br>
<em>&gt; That's another thing academia doesn't do very well.  By the time people
</em><br>
<em>&gt; finish a Ph.D. in *one* field, they might be thirty years old, past their
</em><br>
<em>&gt; annus mirabilis years.  To do AI you need a dozen backgrounds and
</em><br>
<em>&gt; you need
</em><br>
<em>&gt; them when you're young.  Small wonder academia hasn't had much
</em><br>
<em>&gt; luck on AI.
</em><br>
<em>&gt;   Academia places an enormous mountain of unnecessary inconveniences and
</em><br>
<em>&gt; little drains of time in the way of learning and getting the job
</em><br>
<em>&gt; done.  Do
</em><br>
<em>&gt; your homework, teach your classes, publish or perish, compose grant
</em><br>
<em>&gt; proposals, write project reviews, suck up to the faculty... I'm
</em><br>
<em>&gt; not saying
</em><br>
<em>&gt; it's all useless.  Someone has to teach classes.  But it is not
</em><br>
<em>&gt; absolutely
</em><br>
<em>&gt; necessary to solving the problem of Friendly AI.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Nearly all academics are untrained in the way of rationality.  Not
</em><br>
<em>&gt; surprising; few academics are fifth-dan black belts and there are a lot
</em><br>
<em>&gt; more fifth-dan black belts than fifth-dan rationalists.  But if I were in
</em><br>
<em>&gt; academia I would be subject to the authority of those who were
</em><br>
<em>&gt; not Bayesian
</em><br>
<em>&gt; Masters.  In the art of rationality, one seeks to attain the perception
</em><br>
<em>&gt; that most of the things that appear to be reasons and arguments are not
</em><br>
<em>&gt; Bayesian.  Eliminate the distractions, silence the roar of
</em><br>
<em>&gt; cognitive noise,
</em><br>
<em>&gt; and you can finally see the small plain trails of genuine
</em><br>
<em>&gt; evidence.  One of
</em><br>
<em>&gt; my academic friends once asked me to look at a paper on decision theory;
</em><br>
<em>&gt; the paper described the conventional theory, presented a problem,
</em><br>
<em>&gt; and then
</em><br>
<em>&gt; proposed several different individual patches to the conventional theory
</em><br>
<em>&gt; and analyzed the patches individually, concluding that none of the
</em><br>
<em>&gt; solutions were satisfactory.  I replied by arguing that the conventional
</em><br>
<em>&gt; theory actually contained *two* independent foundational errors, which
</em><br>
<em>&gt; needed to be simultaneously refactored to solve the problem, and in fact,
</em><br>
<em>&gt; he needed to look at this whole problem a different way.  And the
</em><br>
<em>&gt; one said:
</em><br>
<em>&gt;   But I have to take the traditional theory as a point of departure and
</em><br>
<em>&gt; then present changes to it, because that's what the reviewers
</em><br>
<em>&gt; will expect.
</em><br>
<em>&gt;   And I said:  Okay, but for myself I don't have to give a damn about
</em><br>
<em>&gt; reviewers, and so I plan to go on using the solution with two
</em><br>
<em>&gt; simultaneous
</em><br>
<em>&gt; corrections.  That bias against two simultaneous changes, owing
</em><br>
<em>&gt; to the need
</em><br>
<em>&gt; to take the conventional theory as a point of departure, was justified as
</em><br>
<em>&gt; necessary by pointing to social forces instead of Bayesian forces.  That
</em><br>
<em>&gt; makes it a distraction.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I refuse to accept that entire class of distractions.  As an independent
</em><br>
<em>&gt; scholar, I never have to give any reason for saying something or thinking
</em><br>
<em>&gt; something that points to social forces instead of the facts of
</em><br>
<em>&gt; the matter.
</em><br>
<em>&gt;   I have the freedom to do the right thing, without the faintest bias
</em><br>
<em>&gt; toward the academically acceptable thing except insofar as the
</em><br>
<em>&gt; academically
</em><br>
<em>&gt; acceptable thing happens to be right.  I have the luxury of
</em><br>
<em>&gt; giving no more
</em><br>
<em>&gt; credence to an idea than the weight of Bayesian evidence calls
</em><br>
<em>&gt; for, even if
</em><br>
<em>&gt; the idea has become fixed in academia through any of the non-Bayesian
</em><br>
<em>&gt; processes that prevail there.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Now, most of the time, I don't second-guess academia - certainly not in
</em><br>
<em>&gt; established fields with great weights of evidence, nor after
</em><br>
<em>&gt; learning just
</em><br>
<em>&gt; the basics of something.  Like I said, it's dangerous to be half a
</em><br>
<em>&gt; rationalist; if you learn the skill of challenging conventional ideas,
</em><br>
<em>&gt; you'd damn well better learn the skill of accepting conventional
</em><br>
<em>&gt; ideas, or
</em><br>
<em>&gt; end up worse off than before.  But sometimes, on the fringes, AI for
</em><br>
<em>&gt; example, people just make stuff up that sounds cool, and it becomes fixed
</em><br>
<em>&gt; because everyone repeats it.  Look at Freudian analysis: not one scrap of
</em><br>
<em>&gt; experimental evidence.  It was a major academic field, with peer-reviewed
</em><br>
<em>&gt; journals and everything, but not the faintest hint of science.  If that's
</em><br>
<em>&gt; the academic standard then academia's standards are too damn low.  Or
</em><br>
<em>&gt; sometimes the people in one field don't know about the results in another
</em><br>
<em>&gt; field, and they say things that are silly and get past the reviewers,
</em><br>
<em>&gt; because the people who could catch the mistake work in a
</em><br>
<em>&gt; different building
</em><br>
<em>&gt; of the college campus.  That likewise happens, *a lot*, in AI.
</em><br>
<em>&gt;
</em><br>
<em>&gt; It seems to me that the secret of effectiveness is refusing to be
</em><br>
<em>&gt; distracted.  At one point in my life I did permit myself to be
</em><br>
<em>&gt; distracted... by writing freelance programs, by planning to start a
</em><br>
<em>&gt; company... eventually I noticed that the only projects in my life
</em><br>
<em>&gt; that had
</em><br>
<em>&gt; ever done the slightest bit of good were the ones that were *directly* on
</em><br>
<em>&gt; track to the Singularity.  *Not* the distraction projects that I thought
</em><br>
<em>&gt; would provide resources or whatever, but the projects that were directly
</em><br>
<em>&gt; part of the critical path to AI.  In 1998 I took one month out of my
</em><br>
<em>&gt; all-important plots to accumulate Singularity resources to write
</em><br>
<em>&gt; &quot;Coding a
</em><br>
<em>&gt; Transhuman AI&quot;, and in the end CaTAI that was the only thing I did that
</em><br>
<em>&gt; year that actually mattered.  And that was very much the story of
</em><br>
<em>&gt; my life,
</em><br>
<em>&gt; until the day I finally snapped and decided to concentrate solely on the
</em><br>
<em>&gt; Singularity.  Today I refuse to be distracted.  Not by academia, not by
</em><br>
<em>&gt; technology companies, not by anything.  All I ask of myself is that I do
</em><br>
<em>&gt; this one thing, solve this one challenge of Friendly AI.
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt; 2.  If lacking a PhD really becomes a problem... well, why not get
</em><br>
<em>&gt; &gt; one? PhD students get living stipends and support for their research.
</em><br>
<em>&gt; &gt; So even being a PhD student may well put Eliezer in a better position
</em><br>
<em>&gt; &gt; to pursue his research than the current scenario allows. Further, if
</em><br>
<em>&gt; &gt; he (or anyone else involved) doesn't like the idea of being forced to
</em><br>
<em>&gt; &gt; take 2 years of coursework for the PhD, he could always pursue the PhD
</em><br>
<em>&gt; &gt; outside of the U.S., where PhDs are pure research degrees with no
</em><br>
<em>&gt; &gt; course requirements.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; 3.  There are a couple of schools (e.g., The University of Technology,
</em><br>
<em>&gt; &gt; Sydney, in Australasia) that award PhDs by prior publication. After
</em><br>
<em>&gt; &gt; applying, you put together a portfolio of your research, and write an
</em><br>
<em>&gt; &gt; overarching paper that illustrates your contribution to the field of
</em><br>
<em>&gt; &gt; study, and if deemed PhD-level, you are granted a PhD. I've come
</em><br>
<em>&gt; &gt; across at least a few professors in the UK and elsewhere who have
</em><br>
<em>&gt; &gt; received their doctorates in this manner. (I've also seen quite a few
</em><br>
<em>&gt; &gt; professors with just Master's, but this falls back to point 2 above).
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Of course, most people aren't aware of some or all of the above
</em><br>
<em>&gt;
</em><br>
<em>&gt; I wasn't aware.  Thanks.  If I don't need to spend eight years, that does
</em><br>
<em>&gt; shift the cost/benefit ratio.  But not far enough, I'm afraid.
</em><br>
<em>&gt;
</em><br>
<em>&gt; --
</em><br>
<em>&gt; Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a>
</em><br>
<em>&gt; Research Fellow, Singularity Institute for Artificial Intelligence
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10079.html">Ben Goertzel: "RE: Why SIAI is a nonprofit"</a>
<li><strong>Previous message:</strong> <a href="10077.html">Giu1i0 Pri5c0: "Re: Why I donate to the SIAI"</a>
<li><strong>In reply to:</strong> <a href="10071.html">Eliezer Yudkowsky: "Why I'm not more involved with academia"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10080.html">Eliezer Yudkowsky: "Re: Why I'm not more involved with academia"</a>
<li><strong>Reply:</strong> <a href="10080.html">Eliezer Yudkowsky: "Re: Why I'm not more involved with academia"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10078">[ date ]</a>
<a href="index.html#10078">[ thread ]</a>
<a href="subject.html#10078">[ subject ]</a>
<a href="author.html#10078">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:49 MDT
</em></small></p>
</body>
</html>
